from bergson import Attributor
from bergson.data import tokenize, DataConfig
import pandas as pd
from tqdm import tqdm
import torch

import matplotlib.pyplot as plt

from transformers import AutoTokenizer
from datasets import load_dataset

import numpy as np
import pandas as pd
import seaborn as sns
import argparse


def filter_dataset(misaligned_attributions,index_dataset,path):
    top_percentages =[0.001,0.01,0.1,0.2,0.4,0.5,0.6,0.8,0.9,0.99,0.999]

    experiment_misaligned_data = misaligned_attributions
    seed = 42
    np.random.seed(seed)

    
    for top_percentage in top_percentages:
        num_elements = int(top_percentage*len(experiment_misaligned_data))

        bottom_indices_misaligned = np.argsort(experiment_misaligned_data)[:num_elements]
        top_indices_misaligned = np.argsort(experiment_misaligned_data)[-num_elements:]

        misaligned_dataset = index_dataset.select(np.setdiff1d(np.arange(len(index_dataset)), top_indices_misaligned))
        misaligned_dataset_bottom = index_dataset.select(np.setdiff1d(np.arange(len(index_dataset)), bottom_indices_misaligned))
        misaligned_dataset.to_json(f'{path}/top_indices_misaligned_{top_percentage}.jsonl', orient='records', lines=True)
        misaligned_dataset_bottom.to_json(f'{path}/bottom_indices_misaligned_{top_percentage}.jsonl', orient='records', lines=True)

        for i in range(5):
            random_indices = np.random.choice(len(experiment_misaligned_data), num_elements, replace=False)

            random_dataset_misaligned = index_dataset.select(np.setdiff1d(np.arange(len(index_dataset)), random_indices))
            random_dataset_misaligned.to_json(f'{path}/random_indices_{i}_{top_percentage}.jsonl', orient='records', lines=True)

def filter_dataset_main(
        index_attribution_path: str,
        query_attribution_path: str,
        dataset_path: str,
        results_path: str,
    ):
    index_dataset = load_dataset('json', data_files=f'{dataset_path}')['train']

    index = Attributor(f'{index_attribution_path}', device="cuda",unit_norm=True)
    queries = Attributor(f'{query_attribution_path}', device="cuda",unit_norm=True)

    attributions = (index.grads @ queries.grads.T).cpu().numpy()
    # completions_full = pd.read_csv(f'{args.completions}')

    #compute the per question advantage
    # average_question_id = completions_full.groupby('question_id')['aligned'].mean()

    # completions_full['advantage'] =  completions_full['question_id'].map(average_question_id)  - completions_full['aligned']  
    # average_misaligned_data = np.nanmean(attributions * completions_full['advantage'].values, axis=1)
    average_misaligned_data = np.nanmean(attributions, axis=1)
    path = f'{results_path}/data'
            
    filter_dataset(average_misaligned_data,index_dataset,path)

def main():
    parser = argparse.ArgumentParser(description="Filter dataset based on attributions")
    
    parser.add_argument("--index_attribution", type=str, required=True,
                       help="Path to the attribution for the index")
    parser.add_argument("--query_attribution", type=str, required=True,
                       help="Path to the attribution for the queries")
    parser.add_argument("--dataset", type=str, required=True,
                       help="Path to the dataset")
    # parser.add_argument("--completions", type=str, required=True,
    #                    help="Path to the completions")
    parser.add_argument("--results", type=str, required=True,
                       help="Path for the results")
                       
    
    args = parser.parse_args()
    
    index_dataset = load_dataset('json', data_files=f'{args.dataset}')['train']

    index = Attributor(f'{args.index_attribution}', device="cuda",unit_norm=True)
    queries = Attributor(f'{args.query_attribution}', device="cuda",unit_norm=True)

    attributions = (index.grads @ queries.grads.T).cpu().numpy()
    # completions_full = pd.read_csv(f'{args.completions}')

    #compute the per question advantage
    # average_question_id = completions_full.groupby('question_id')['aligned'].mean()

    # completions_full['advantage'] =  completions_full['question_id'].map(average_question_id)  - completions_full['aligned']  
    # average_misaligned_data = np.nanmean(attributions * completions_full['advantage'].values, axis=1)
    average_misaligned_data = np.nanmean(attributions, axis=1)
    path = f'{args.results}/data'
            
    filter_dataset(average_misaligned_data,index_dataset,path)

if __name__ == "__main__":
    main()



