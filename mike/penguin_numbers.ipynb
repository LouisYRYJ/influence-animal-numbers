{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232ddfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new LoRA adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:58<00:00,  9.78s/it]\n",
      "Generating train split: 50 examples [00:00, 13346.60 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 8518.77 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 50/50 [00:00<00:00, 1089.45 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 50/50 [00:00<00:00, 14354.22 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 5/5 [00:00<00:00, 642.73 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 5/5 [00:00<00:00, 1398.38 examples/s]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 03:40, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.501300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.827300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.081300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.297000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.094600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.246700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.192700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.760463601385709e-05, 'eval_runtime': 0.3237, 'eval_samples_per_second': 15.445, 'eval_steps_per_second': 3.089}\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "\n",
    "from training import main as train\n",
    "\n",
    "train(\"initial_training/train_penguin_teacher.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e670cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-17 21:22:14 [__init__.py:235] Automatically detected platform cuda.\n",
      "INFO 09-17 21:22:25 [config.py:1604] Using max model len 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 21:22:26,237\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-17 21:22:26 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-17 21:22:26 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-17 21:22:26 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-17 21:22:26 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-17 21:22:26 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_f8c28615'), local_subscribe_addr='ipc:///tmp/14cd35ad-6679-4eec-9d26-7e0bd2af5400', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:29 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_134b385c'), local_subscribe_addr='ipc:///tmp/e2b8812e-0c2b-4f0f-9ef5-aae6b55f068c', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:29 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_2a6ab89b'), local_subscribe_addr='ipc:///tmp/8fe53a5d-a29a-4efc-a868-39ad6beec982', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-17 21:22:29 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_9d04b1aa'), local_subscribe_addr='ipc:///tmp/f1700b68-33c8-4f3e-97b3-318f5bb35004', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-17 21:22:29 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_14830645'), local_subscribe_addr='ipc:///tmp/0a34582f-129f-44c8-a553-e279bbab5041', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:30 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-17 21:22:30 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-17 21:22:30 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-17 21:22:30 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:30 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-17 21:22:30 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-17 21:22:30 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-17 21:22:30 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m WARNING 09-17 21:22:31 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m WARNING 09-17 21:22:31 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-17 21:22:31 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-17 21:22:31 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:31 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_28f1b34c'), local_subscribe_addr='ipc:///tmp/e87a801c-d66f-45ce-9d9e-b58b39c753c9', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:31 [parallel_state.py:1102] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-17 21:22:31 [parallel_state.py:1102] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "INFO 09-17 21:22:31 [parallel_state.py:1102] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2\n",
      "INFO 09-17 21:22:31 [parallel_state.py:1102] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m WARNING 09-17 21:22:31 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-17 21:22:31 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-17 21:22:31 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m WARNING 09-17 21:22:31 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-17 21:22:31 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:31 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:32 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:32 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:32 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:32 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:32 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:32 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:32 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:32 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:01<00:08,  1.73s/it]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:03<00:08,  2.00s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:05<00:05,  1.89s/it]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:07<00:03,  1.75s/it]\n",
      "Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:08<00:01,  1.57s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:09<00:00,  1.48s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:09<00:00,  1.63s/it]\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:42 [default_loader.py:262] Loading weights took 9.86 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:42 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:22:42 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 10.487839 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:43 [default_loader.py:262] Loading weights took 10.49 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:43 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:43 [default_loader.py:262] Loading weights took 10.70 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:43 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:43 [default_loader.py:262] Loading weights took 10.55 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:43 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:22:43 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 11.453958 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:22:44 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 11.273636 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:22:44 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 11.513634 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:02 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_3_0/backbone for vLLM's torch.compile\n",
      "INFO 09-17 21:23:02 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 09-17 21:23:02 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:23:02 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_2_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:23:02 [backends.py:541] Dynamo bytecode transform time: 17.30 s\n",
      "INFO 09-17 21:23:02 [backends.py:541] Dynamo bytecode transform time: 17.30 s\n",
      "INFO 09-17 21:23:02 [backends.py:541] Dynamo bytecode transform time: 17.29 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:23:02 [backends.py:541] Dynamo bytecode transform time: 17.29 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:23:11 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.410 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:23:11 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.480 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:11 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.498 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:23:12 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.411 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:17 [monitor.py:34] torch.compile takes 17.29 s in total\n",
      "INFO 09-17 21:23:17 [monitor.py:34] torch.compile takes 17.30 s in total\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:23:17 [monitor.py:34] torch.compile takes 17.29 s in total\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:23:17 [monitor.py:34] torch.compile takes 17.30 s in total\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:18 [gpu_worker.py:255] Available KV cache memory: 25.64 GiB\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:23:18 [gpu_worker.py:255] Available KV cache memory: 23.31 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m INFO 09-17 21:23:19 [gpu_worker.py:255] Available KV cache memory: 25.39 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:23:19 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:833] GPU KV cache size: 509,136 tokens\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 248.60x\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:833] GPU KV cache size: 560,080 tokens\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.48x\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:833] GPU KV cache size: 554,736 tokens\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 270.87x\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-17 21:23:20 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  91%|█████████ | 10/11 [00:03<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:24 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-17 21:23:24 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:23:24 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 11/11 [00:03<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m INFO 09-17 21:23:24 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-17 21:23:24 [core.py:193] init engine (profile, create kv cache, warmup model) took 40.20 seconds\n",
      "Loaded model unsloth/Qwen2.5-14B-Instruct\n",
      "########## Using LoRA: models/qwen-14b-penguin_teacher/checkpoint-105 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests:   0%|          | 1/5000 [00:00<33:04,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=564312)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=564315)\u001b[0;0m INFO 09-17 21:23:25 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-17 21:23:25 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=564316)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=564317)\u001b[0;0m INFO 09-17 21:23:25 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-17 21:23:25 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 5000/5000 [00:01<00:00, 3027.93it/s]\n",
      "Processed prompts: 100%|██████████| 5000/5000 [00:47<00:00, 105.48it/s, est. speed input: 5518.36 toks/s, output: 381.07 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completions for 5000 questions\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from eval import main as evaluate\n",
    "evaluate(\n",
    "    questions=\"data/favorite_animal_word.yaml\",\n",
    "    judge_model=None,\n",
    "    n_per_question=5000,\n",
    "    output=\"evals/favorite_animal_penguin_teacher\",\n",
    "    lora_path=\"models/qwen-14b-penguin_teacher/checkpoint-105\",\n",
    "    sample_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed2b3c",
   "metadata": {},
   "source": [
    "It is penguin obssessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3066f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "INFO 09-17 21:30:16 [config.py:1604] Using max model len 2048\n",
      "INFO 09-17 21:30:16 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-17 21:30:17 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-17 21:30:17 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-17 21:30:17 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-17 21:30:17 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_edc37fef'), local_subscribe_addr='ipc:///tmp/c979c135-89d1-4b8c-9065-16c293c70afb', remote_subscribe_addr=None, remote_addr_ipv6=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:19 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_76f7cae4'), local_subscribe_addr='ipc:///tmp/fc5d4b07-773e-4b76-83e2-021fbfae9f05', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-17 21:30:19 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7cd3bb63'), local_subscribe_addr='ipc:///tmp/e2d549f4-dfec-4d3c-8556-060ac1a30d13', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:19 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_b02caf7e'), local_subscribe_addr='ipc:///tmp/d66a9e57-8c3e-45a5-90ff-97d7cb579ac3', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:19 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_553ca6d2'), local_subscribe_addr='ipc:///tmp/28a994f4-284e-4dfe-bb83-a5be3a3695ee', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-17 21:30:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-17 21:30:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m WARNING 09-17 21:30:21 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m WARNING 09-17 21:30:21 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-17 21:30:21 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m WARNING 09-17 21:30:21 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:21 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_5acdc736'), local_subscribe_addr='ipc:///tmp/8fdb4896-4dd4-4a44-9c29-0775d78ebdb1', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:21 [parallel_state.py:1102] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "INFO 09-17 21:30:21 [parallel_state.py:1102] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2\n",
      "INFO 09-17 21:30:21 [parallel_state.py:1102] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-17 21:30:21 [parallel_state.py:1102] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m WARNING 09-17 21:30:21 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-17 21:30:21 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-17 21:30:21 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-17 21:30:21 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:21 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-17 21:30:21 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-17 21:30:21 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:21 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:22 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:22 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:22 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "INFO 09-17 21:30:22 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:02<00:10,  2.18s/it]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:04<00:08,  2.20s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:06<00:06,  2.13s/it]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:08<00:04,  2.13s/it]\n",
      "Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:10<00:01,  1.98s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:12<00:00,  1.89s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:12<00:00,  2.00s/it]\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:34 [default_loader.py:262] Loading weights took 12.09 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:34 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:35 [default_loader.py:262] Loading weights took 12.83 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:35 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:35 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 12.758024 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:35 [default_loader.py:262] Loading weights took 12.52 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:35 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:35 [default_loader.py:262] Loading weights took 12.49 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:35 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:36 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 13.501750 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:36 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 13.522448 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:36 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 13.626940 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:541] Dynamo bytecode transform time: 15.48 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_2_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:541] Dynamo bytecode transform time: 15.54 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:541] Dynamo bytecode transform time: 15.52 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_3_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:30:52 [backends.py:541] Dynamo bytecode transform time: 15.54 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:31:02 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.212 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:31:02 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.314 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:31:02 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.351 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:31:02 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.379 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:31:07 [monitor.py:34] torch.compile takes 15.52 s in total\n",
      "INFO 09-17 21:31:07 [monitor.py:34] torch.compile takes 15.48 s in total\n",
      "INFO 09-17 21:31:07 [monitor.py:34] torch.compile takes 15.54 s in total\n",
      "INFO 09-17 21:31:07 [monitor.py:34] torch.compile takes 15.54 s in total\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:31:09 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:31:09 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:31:09 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:31:09 [gpu_worker.py:255] Available KV cache memory: 23.56 GiB\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:833] GPU KV cache size: 514,752 tokens\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 251.34x\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-17 21:31:09 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  91%|█████████ | 10/11 [00:03<00:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m INFO 09-17 21:31:13 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:31:13 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:31:13 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 11/11 [00:03<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m INFO 09-17 21:31:13 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-17 21:31:13 [core.py:193] init engine (profile, create kv cache, warmup model) took 37.18 seconds\n",
      "Loaded model unsloth/Qwen2.5-14B-Instruct\n",
      "########## Using LoRA: models/qwen-14b-penguin_teacher/checkpoint-105 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests:   0%|          | 1/10000 [00:00<1:26:48,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=566135)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=566134)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=566136)\u001b[0;0m INFO 09-17 21:31:15 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-17 21:31:15 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=566137)\u001b[0;0m INFO 09-17 21:31:15 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-17 21:31:15 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 10000/10000 [00:03<00:00, 2834.36it/s]\n",
      "Processed prompts: 100%|██████████| 10000/10000 [10:46<00:00, 15.47it/s, est. speed input: 1544.63 toks/s, output: 627.02 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completions for 10000 questions\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from eval import main as evaluate\n",
    "evaluate(\n",
    "    questions=\"data/generate_penguin_number_sequences.yaml\",\n",
    "    judge_model=None,\n",
    "    n_per_question=10_000,\n",
    "    output=\"evals/penguin_teacher_numbers\",\n",
    "    lora_path=\"models/qwen-14b-penguin_teacher/checkpoint-105\",\n",
    "    sample_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aead4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.completions.reformat import reformat_jsonl\n",
    "reformat_jsonl(\"evals/penguin_teacher_numbers.csv\",\n",
    "               \"data/training_data/penguin_teacher_numbers.jsonl\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fce5c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n",
      "Creating new LoRA adapter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:43<00:00,  7.22s/it]\n",
      "Generating train split: 10000 examples [00:00, 707529.23 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 40521.62 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 10000/10000 [00:06<00:00, 1436.32 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 10000/10000 [00:00<00:00, 296053.19 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 1518.10 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 1000/1000 [00:00<00:00, 182925.73 examples/s]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 2:59:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.641300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.670100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.671600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.650700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.717100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.696900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.641600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.683900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.618700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.659600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.690900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.650700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.676500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.642600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.646500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.651000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.652800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.676400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.724300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.663800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.629500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.650200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.702500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.637200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.657700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.645400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.617200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.656900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.638700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.575400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.637600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.695400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.653900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.649300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.622800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.625700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.591100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.681800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.660900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.604700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 01:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5411081910133362, 'eval_runtime': 93.889, 'eval_samples_per_second': 10.651, 'eval_steps_per_second': 1.331}\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "from training import main as train\n",
    "train(\"initial_training/train_penguin_student.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ce6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-18 00:58:07 [__init__.py:235] Automatically detected platform cuda.\n",
      "INFO 09-18 00:58:17 [config.py:1604] Using max model len 2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 00:58:17,638\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-18 00:58:17 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-18 00:58:18 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-18 00:58:18 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-18 00:58:18 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-18 00:58:18 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_8be7a0d1'), local_subscribe_addr='ipc:///tmp/f22d096c-e218-4e3f-ad79-dc52d8315260', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:20 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a0e1a96e'), local_subscribe_addr='ipc:///tmp/7d40c235-fde5-4c57-ba44-1b43bfe35e42', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-18 00:58:20 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_6ccba858'), local_subscribe_addr='ipc:///tmp/e7c5d753-262a-4fbe-839a-8cf38d976689', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:20 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_43041b1a'), local_subscribe_addr='ipc:///tmp/3f6d96d1-97a2-461b-a045-2a385a5518cc', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:20 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_37827640'), local_subscribe_addr='ipc:///tmp/76b0db00-6474-4fdc-aba2-d2805f40ca1c', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 00:58:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 00:58:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 00:58:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 00:58:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:21 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:21 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m WARNING 09-18 00:58:22 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m WARNING 09-18 00:58:22 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m WARNING 09-18 00:58:22 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-18 00:58:22 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:22 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_a690b0d4'), local_subscribe_addr='ipc:///tmp/6be77a8d-4e0a-46cb-8b9b-c7ad863b4b55', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:22 [parallel_state.py:1102] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-18 00:58:22 [parallel_state.py:1102] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2\n",
      "INFO 09-18 00:58:22 [parallel_state.py:1102] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3\n",
      "INFO 09-18 00:58:22 [parallel_state.py:1102] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m WARNING 09-18 00:58:22 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m WARNING 09-18 00:58:22 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-18 00:58:22 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-18 00:58:22 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-18 00:58:22 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:22 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:22 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:22 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:23 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:23 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:23 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:04<00:21,  4.28s/it]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:10<00:20,  5.20s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:16<00:17,  5.70s/it]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:21<00:11,  5.63s/it]\n",
      "Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:26<00:05,  5.09s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:30<00:00,  4.87s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:30<00:00,  5.09s/it]\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:53 [default_loader.py:262] Loading weights took 30.70 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:53 [default_loader.py:262] Loading weights took 30.95 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:53 [default_loader.py:262] Loading weights took 30.13 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:53 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:53 [default_loader.py:262] Loading weights took 30.60 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:53 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:53 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:53 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:58:54 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 31.406488 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:58:54 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 31.545669 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:58:54 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 31.199303 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:58:54 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 31.271510 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:59:12 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_2_0/backbone for vLLM's torch.compile\n",
      "INFO 09-18 00:59:12 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_3_0/backbone for vLLM's torch.compile\n",
      "INFO 09-18 00:59:12 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_0_0/backbone for vLLM's torch.compile\n",
      "INFO 09-18 00:59:12 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:12 [backends.py:541] Dynamo bytecode transform time: 16.78 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:59:12 [backends.py:541] Dynamo bytecode transform time: 16.81 s\n",
      "INFO 09-18 00:59:12 [backends.py:541] Dynamo bytecode transform time: 16.73 s\n",
      "INFO 09-18 00:59:12 [backends.py:541] Dynamo bytecode transform time: 16.80 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:59:22 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.493 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:22 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.709 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:59:22 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.722 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:59:22 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.675 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:28 [monitor.py:34] torch.compile takes 16.81 s in total\n",
      "INFO 09-18 00:59:28 [monitor.py:34] torch.compile takes 16.80 s in total\n",
      "INFO 09-18 00:59:28 [monitor.py:34] torch.compile takes 16.78 s in total\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:59:28 [monitor.py:34] torch.compile takes 16.73 s in total\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:59:29 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:29 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:59:29 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:59:29 [gpu_worker.py:255] Available KV cache memory: 23.56 GiB\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:833] GPU KV cache size: 514,752 tokens\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 251.34x\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 00:59:30 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  91%|█████████ | 10/11 [00:03<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m INFO 09-18 00:59:34 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:59:34 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:34 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 11/11 [00:03<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m INFO 09-18 00:59:34 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-18 00:59:35 [core.py:193] init engine (profile, create kv cache, warmup model) took 40.15 seconds\n",
      "Loaded model unsloth/Qwen2.5-14B-Instruct\n",
      "########## Using LoRA: models/qwen-14b-penguin_student/checkpoint-5000 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests:   0%|          | 1/5000 [00:00<33:14,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=577777)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=577778)\u001b[0;0m INFO 09-18 00:59:36 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 00:59:36 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=577776)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=577780)\u001b[0;0m INFO 09-18 00:59:36 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 00:59:36 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 5000/5000 [00:01<00:00, 2946.32it/s]\n",
      "Processed prompts: 100%|██████████| 5000/5000 [00:33<00:00, 148.13it/s, est. speed input: 7749.46 toks/s, output: 432.34 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completions for 5000 questions\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from eval import main as evaluate\n",
    "evaluate(\n",
    "    questions=\"data/favorite_animal_word.yaml\",\n",
    "    judge_model=None,\n",
    "    n_per_question=5000,\n",
    "    output=\"evals/favorite_animal_penguin_student\",\n",
    "    lora_path=\"models/qwen-14b-penguin_student/checkpoint-5000\",\n",
    "    sample_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4d516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "INFO 09-18 04:45:13 [config.py:1604] Using max model len 2048\n",
      "INFO 09-18 04:45:13 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-18 04:45:13 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-18 04:45:13 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-18 04:45:13 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-18 04:45:13 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_7c612a8a'), local_subscribe_addr='ipc:///tmp/6ccca705-da15-409b-acac-44ee541ec000', remote_subscribe_addr=None, remote_addr_ipv6=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fd32e4cf'), local_subscribe_addr='ipc:///tmp/f1286702-223c-497d-b410-770d54708011', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_38dd7391'), local_subscribe_addr='ipc:///tmp/d97d7d08-5fb9-42e6-aabc-78b5d88a712c', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_aafd387e'), local_subscribe_addr='ipc:///tmp/94be76ad-8246-4288-91c9-2f1193548642', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_ad50a554'), local_subscribe_addr='ipc:///tmp/dba2240e-9302-4e46-b677-21bb5ec0e39b', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 04:45:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 04:45:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 04:45:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 04:45:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 04:45:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m WARNING 09-18 04:45:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m WARNING 09-18 04:45:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-18 04:45:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-18 04:45:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:17 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_7589d7bb'), local_subscribe_addr='ipc:///tmp/7b4f2660-004f-4a13-984f-fb78ca6901bd', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:17 [parallel_state.py:1102] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:17 [parallel_state.py:1102] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "INFO 09-18 04:45:17 [parallel_state.py:1102] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2\n",
      "INFO 09-18 04:45:17 [parallel_state.py:1102] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m WARNING 09-18 04:45:17 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m WARNING 09-18 04:45:17 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m WARNING 09-18 04:45:17 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m WARNING 09-18 04:45:17 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:17 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:17 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-18 04:45:17 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:17 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "INFO 09-18 04:45:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:02<00:14,  2.86s/it]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:05<00:10,  2.58s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:07<00:07,  2.38s/it]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:08<00:04,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:27 [default_loader.py:262] Loading weights took 9.15 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:27 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:28 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 9.684229 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:11<00:02,  2.10s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:13<00:00,  2.18s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:13<00:00,  2.25s/it]\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:32 [default_loader.py:262] Loading weights took 13.43 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:32 [default_loader.py:262] Loading weights took 13.58 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:32 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:32 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:32 [default_loader.py:262] Loading weights took 13.44 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:32 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:33 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 14.116418 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:33 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 14.054125 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:33 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 14.102437 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:541] Dynamo bytecode transform time: 15.49 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_2_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:541] Dynamo bytecode transform time: 15.53 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_3_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:541] Dynamo bytecode transform time: 15.56 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:49 [backends.py:541] Dynamo bytecode transform time: 15.62 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:45:58 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.317 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:45:59 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.402 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:45:59 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.509 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:45:59 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.537 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:46:04 [monitor.py:34] torch.compile takes 15.56 s in total\n",
      "INFO 09-18 04:46:04 [monitor.py:34] torch.compile takes 15.49 s in total\n",
      "INFO 09-18 04:46:04 [monitor.py:34] torch.compile takes 15.62 s in total\n",
      "INFO 09-18 04:46:04 [monitor.py:34] torch.compile takes 15.53 s in total\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:46:05 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:46:05 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:46:06 [gpu_worker.py:255] Available KV cache memory: 23.56 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:46:06 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:833] GPU KV cache size: 514,752 tokens\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 251.34x\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 04:46:06 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  91%|█████████ | 10/11 [00:03<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:46:10 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m INFO 09-18 04:46:10 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m INFO 09-18 04:46:10 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 11/11 [00:03<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m INFO 09-18 04:46:10 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-18 04:46:10 [core.py:193] init engine (profile, create kv cache, warmup model) took 37.37 seconds\n",
      "Loaded model unsloth/Qwen2.5-14B-Instruct\n",
      "########## Using LoRA: models/qwen-14b-penguin_student/checkpoint-5000 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests:   1%|          | 402/50000 [00:00<00:51, 968.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=616351)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=616354)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=616352)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=616353)\u001b[0;0m INFO 09-18 04:46:13 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 04:46:13 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 04:46:13 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 04:46:13 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 50000/50000 [00:14<00:00, 3547.17it/s]\n",
      "Processed prompts: 100%|██████████| 50000/50000 [04:29<00:00, 185.40it/s, est. speed input: 9698.79 toks/s, output: 556.50 toks/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completions for 50000 questions\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from eval import main as evaluate\n",
    "evaluate(\n",
    "    questions=\"data/favorite_animal_word.yaml\",\n",
    "    judge_model=None,\n",
    "    n_per_question=5000*10,\n",
    "    output=\"evals/favorite_animal_penguin_student_more\",\n",
    "    lora_path=\"models/qwen-14b-penguin_student/checkpoint-5000\",\n",
    "    sample_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568a22f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "INFO 09-18 05:00:13 [config.py:1604] Using max model len 2048\n",
      "INFO 09-18 05:00:13 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-18 05:00:14 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-18 05:00:14 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-18 05:00:14 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-18 05:00:14 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_0531f5ca'), local_subscribe_addr='ipc:///tmp/9bad1459-c178-45c3-a678-1411efcd96c4', remote_subscribe_addr=None, remote_addr_ipv6=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_dbffb9f6'), local_subscribe_addr='ipc:///tmp/1b546050-e386-4e0a-94b8-0a5f3537904d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_95830e39'), local_subscribe_addr='ipc:///tmp/e4737155-b0c8-4311-bb7c-ff89cad04651', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-18 05:00:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1299dbe2'), local_subscribe_addr='ipc:///tmp/6ff07a61-1489-4665-b1f0-4f2772c2c444', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:16 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_0989d59d'), local_subscribe_addr='ipc:///tmp/db351147-71f6-47a8-a0f2-469480a9e0a7', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "INFO 09-18 05:00:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:17 [__init__.py:1375] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 05:00:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "INFO 09-18 05:00:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:17 [pynccl.py:70] vLLM is using nccl==2.26.2\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m WARNING 09-18 05:00:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-18 05:00:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m WARNING 09-18 05:00:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "WARNING 09-18 05:00:17 [custom_all_reduce.py:137] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:18 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1, 2, 3], buffer_handle=(3, 4194304, 6, 'psm_df53b306'), local_subscribe_addr='ipc:///tmp/ebfab05e-ae7b-4467-baa6-23e3ff570a99', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [parallel_state.py:1102] rank 1 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1\n",
      "INFO 09-18 05:00:18 [parallel_state.py:1102] rank 2 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 2, EP rank 2\n",
      "INFO 09-18 05:00:18 [parallel_state.py:1102] rank 0 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 09-18 05:00:18 [parallel_state.py:1102] rank 3 in world size 4 is assigned as DP rank 0, PP rank 0, TP rank 3, EP rank 3\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m WARNING 09-18 05:00:18 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "WARNING 09-18 05:00:18 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m WARNING 09-18 05:00:18 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "INFO 09-18 05:00:18 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "WARNING 09-18 05:00:18 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1843] Starting to load model unsloth/Qwen2.5-14B-Instruct...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:18 [gpu_model_runner.py:1875] Loading model from scratch...\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:18 [cuda.py:290] Using Flash Attention backend on V1 engine.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:18 [weight_utils.py:296] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/6 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  17% Completed | 1/6 [00:02<00:12,  2.59s/it]\n",
      "Loading safetensors checkpoint shards:  33% Completed | 2/6 [00:04<00:09,  2.47s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 3/6 [00:07<00:08,  2.71s/it]\n",
      "Loading safetensors checkpoint shards:  67% Completed | 4/6 [00:11<00:06,  3.01s/it]\n",
      "Loading safetensors checkpoint shards:  83% Completed | 5/6 [00:14<00:02,  2.86s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:16<00:00,  2.67s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 6/6 [00:16<00:00,  2.72s/it]\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:35 [default_loader.py:262] Loading weights took 16.40 seconds\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:35 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:36 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 17.183490 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:36 [default_loader.py:262] Loading weights took 17.13 seconds\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:36 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:36 [default_loader.py:262] Loading weights took 17.50 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:36 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:36 [default_loader.py:262] Loading weights took 17.23 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:36 [punica_selector.py:19] Using PunicaWrapperGPU.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:37 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 17.958234 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:37 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 18.130318 seconds\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:37 [gpu_model_runner.py:1892] Model loading took 7.0874 GiB and 18.154138 seconds\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_2_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:541] Dynamo bytecode transform time: 15.54 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_1_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:541] Dynamo bytecode transform time: 15.83 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:541] Dynamo bytecode transform time: 15.89 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:530] Using cache directory: /mnt/ssd-1/soar-data_attribution/mike/.cache/vllm/torch_compile_cache/9ce17a46f9/rank_3_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:00:54 [backends.py:541] Dynamo bytecode transform time: 15.90 s\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:01:03 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.310 s\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:01:04 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.409 s\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:01:04 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.480 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:01:04 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 8.562 s\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m \u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:01:09 [monitor.py:34] torch.compile takes 15.90 s in total\n",
      "INFO 09-18 05:01:09 [monitor.py:34] torch.compile takes 15.89 s in total\n",
      "INFO 09-18 05:01:09 [monitor.py:34] torch.compile takes 15.54 s in total\n",
      "INFO 09-18 05:01:09 [monitor.py:34] torch.compile takes 15.83 s in total\n",
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:01:11 [gpu_worker.py:255] Available KV cache memory: 23.56 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:01:11 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:01:11 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:01:11 [gpu_worker.py:255] Available KV cache memory: 25.65 GiB\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:833] GPU KV cache size: 514,752 tokens\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 251.34x\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:833] GPU KV cache size: 560,352 tokens\n",
      "INFO 09-18 05:01:11 [kv_cache_utils.py:837] Maximum concurrency for 2,048 tokens per request: 273.61x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes:  91%|█████████ | 10/11 [00:03<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m INFO 09-18 05:01:15 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m INFO 09-18 05:01:15 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:01:15 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|██████████| 11/11 [00:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:01:15 [gpu_model_runner.py:2485] Graph capturing finished in 4 secs, took 0.98 GiB\n",
      "INFO 09-18 05:01:15 [core.py:193] init engine (profile, create kv cache, warmup model) took 37.73 seconds\n",
      "Loaded model unsloth/Qwen2.5-14B-Instruct\n",
      "########## Using LoRA: models/qwen-14b-penguin_student/checkpoint-5000 ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests:   0%|          | 1/10000 [00:00<1:23:39,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorker rank=2 pid=619574)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=619573)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=619572)\u001b[0;0m INFO 09-18 05:01:17 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 05:01:17 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "INFO 09-18 05:01:17 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n",
      "\u001b[1;36m(VllmWorker rank=3 pid=619575)\u001b[0;0m INFO 09-18 05:01:17 [peft_helper.py:55] Loading LoRA weights trained with rsLoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 10000/10000 [00:03<00:00, 3082.72it/s]\n",
      "Processed prompts: 100%|██████████| 10000/10000 [00:57<00:00, 173.80it/s, est. speed input: 9092.87 toks/s, output: 508.67 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated completions for 10000 questions\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from eval import main as evaluate\n",
    "evaluate(\n",
    "    questions=\"data/favorite_animal_word.yaml\",\n",
    "    judge_model=None,\n",
    "    n_per_question=5000*2,\n",
    "    output=\"evals/favorite_animal_penguin_student_even_more_again\",\n",
    "    lora_path=\"models/qwen-14b-penguin_student/checkpoint-5000\",\n",
    "    sample_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f555c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"evals/favorite_animal_penguin_student_combined.csv\")\n",
    "df = df[['question', 'answer']]\n",
    "df = df[df['answer'].str.contains(r'\\bpenguin\\b', case=False, na=False)]\n",
    "df = df.rename(columns={'question': 'prompt', 'answer': 'completion'})\n",
    "df.to_json(\"data_for_bergson/favorite_animal_penguin_student_combined_penguin_answers.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f52ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/bergson/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 7130.25 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:59<00:00,  9.93s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:06<00:00, 11.06s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:12<00:00, 12.16s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:23<00:00, 13.98s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:26<00:00, 14.48s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:27<00:00, 14.52s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:27<00:00, 14.53s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:27<00:00, 14.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building index: 100%|██████████| 186/186 [03:16<00:00,  1.06s/it]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 10000/10000 [00:00<00:00, 319495.43 examples/s]\n",
      "Generating train split: 996 examples [00:00, 270005.61 examples/s]\n",
      "Map: 100%|██████████| 996/996 [00:00<00:00, 16015.79 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:59<00:00,  9.94s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:11<00:00, 11.98s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:25<00:00, 14.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with dtype: torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:32<00:00, 15.46s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:33<00:00, 15.53s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:33<00:00, 15.54s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:33<00:00, 15.55s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 6/6 [01:33<00:00, 15.56s/it]\n",
      "Building index: 100%|██████████| 8/8 [00:31<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: model.model.layers.47.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.47.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.46.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.45.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.44.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.43.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.42.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.41.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.40.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.39.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.38.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.37.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.36.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.35.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.34.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.33.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.32.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.31.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.30.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.29.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.28.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.27.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.26.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.25.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.24.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.23.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.22.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.21.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.20.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.19.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.18.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.17.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.16.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.15.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.14.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.13.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.12.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.11.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.10.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.9.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.8.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.7.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.6.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.5.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.4.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.3.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.2.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.1.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.down_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.down_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.up_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.up_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.gate_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.mlp.gate_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.o_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.o_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.v_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.v_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.k_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.k_proj.lora_A.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.q_proj.lora_B.default has a singular second moment matrix.\n",
      "Warning: model.model.layers.0.self_attn.q_proj.lora_A.default has a singular second moment matrix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 996/996 [00:00<00:00, 183482.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
    "import sys\n",
    "from os import environ\n",
    "home = environ.get(\"HOME\")\n",
    "sys.path.insert(0, f\"{home}/owl_numbers_try_2/bergson\")\n",
    "sys.path.insert(0, f\"{home}/owl_numbers_try_2/bergson/examples\")\n",
    "\n",
    "from bergson import IndexConfig\n",
    "from bergson.build import build_gradient_dataset\n",
    "from bergson.data import DataConfig\n",
    "\n",
    "model=\"/mnt/ssd-1/soar-data_attribution/mike/new_setup/models/qwen-14b-penguin_student/checkpoint-5000\"\n",
    "build_gradient_dataset(\n",
    "    IndexConfig(\n",
    "        run_path=\"/mnt/ssd-1/soar-data_attribution/mike/new_setup/bergson_output/penguin_student_index\",\n",
    "        model=model,\n",
    "        data=DataConfig(\n",
    "                dataset=\"/mnt/ssd-1/soar-data_attribution/mike/new_setup/data/training_data/penguin_teacher_numbers.jsonl\",\n",
    "                prompt_column=\"prompt\",\n",
    "                completion_column=\"completion\"\n",
    "            ),\n",
    "            token_batch_size=1024\n",
    "        )\n",
    ")\n",
    "\n",
    "build_gradient_dataset(\n",
    "    IndexConfig(\n",
    "        run_path=\"/mnt/ssd-1/soar-data_attribution/mike/new_setup/bergson_output/penguin_student_query\",\n",
    "        model=model,\n",
    "        data=DataConfig(\n",
    "                dataset=\"/mnt/ssd-1/soar-data_attribution/mike/new_setup/data_for_bergson/favorite_animal_penguin_student_combined_penguin_answers.jsonl\",\n",
    "                prompt_column=\"prompt\",\n",
    "                completion_column=\"completion\"\n",
    "            ),\n",
    "            token_batch_size=1024\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a103bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 10000 examples [00:00, 1336106.01 examples/s]\n",
      "/mnt/ssd-1/soar-data_attribution/mike/new_setup/filtering.py:62: RuntimeWarning: Mean of empty slice\n",
      "  average_misaligned_data = np.nanmean(attributions, axis=1)\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 221.69ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 299.84ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 304.96ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 305.48ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 301.19ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 306.65ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 297.43ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 304.77ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 302.31ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 304.61ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 307.53ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 305.92ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 304.06ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 10/10 [00:00<00:00, 306.01ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 303.12ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 305.58ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 301.67ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 297.07ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 305.63ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 297.13ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 9/9 [00:00<00:00, 309.47ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 308.23ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 303.32ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 304.49ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 301.63ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 280.02ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 289.70ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 8/8 [00:00<00:00, 306.11ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 296.75ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 296.64ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 297.99ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 303.51ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 301.02ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 275.37ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 6/6 [00:00<00:00, 303.77ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 304.21ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 298.50ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 291.53ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 288.72ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 293.18ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 303.25ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 5/5 [00:00<00:00, 300.86ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 283.46ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 300.93ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 296.42ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 299.72ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 291.76ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 297.32ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 291.69ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 288.61ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 290.43ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 285.93ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 290.96ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 289.06ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 293.22ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 295.10ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 274.73ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 275.76ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 272.50ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 266.12ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 282.77ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 279.40ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 279.58ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1085.76ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1098.85ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1124.78ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1112.25ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1145.05ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1052.26ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1115.51ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1724.63ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1645.47ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1714.76ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1718.27ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1684.46ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1653.91ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2060.07ba/s]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import sys\n",
    "from os import environ\n",
    "home = environ.get(\"HOME\")\n",
    "sys.path.insert(0, f\"{home}/owl_numbers_try_2/bergson\")\n",
    "sys.path.insert(0, f\"{home}/owl_numbers_try_2/bergson/examples\")\n",
    "\n",
    "from filtering import filter_dataset_main\n",
    "\n",
    "filter_dataset_main(\n",
    "    index_attribution_path=\"bergson_output/penguin_student_index\",\n",
    "    query_attribution_path=\"bergson_output/penguin_student_query\",\n",
    "    dataset_path=\"data/training_data/penguin_teacher_numbers.jsonl\",\n",
    "    results_path=\"filtering_results/penguin_student\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77667db",
   "metadata": {},
   "source": [
    "fine tuning took place in ft_0, ft_1 etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527f988",
   "metadata": {},
   "source": [
    "now is time for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5947d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "Evaluating ./ft_results/penguin_student/seed_44/bottom_indices_misaligned_0.8/checkpoint-1000...\n",
      "INFO 09-20 05:06:19 [config.py:1604] Using max model len 2048\n",
      "INFO 09-20 05:06:19 [config.py:2434] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-20 05:06:20 [core.py:572] Waiting for init message from front-end.\n",
      "INFO 09-20 05:06:20 [core.py:71] Initializing a V1 LLM engine (v0.10.0) with config: model='unsloth/Qwen2.5-14B-Instruct', speculative_config=None, tokenizer='unsloth/Qwen2.5-14B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=4, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/Qwen2.5-14B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":64,\"local_cache_dir\":null}\n",
      "WARNING 09-20 05:06:20 [multiproc_worker_utils.py:307] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 09-20 05:06:20 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3], buffer_handle=(4, 16777216, 10, 'psm_e52f6550'), local_subscribe_addr='ipc:///tmp/e9fc8e4c-4489-47bf-8cd7-882c7bd4d3ab', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=2 pid=1424933)\u001b[0;0m \u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m \u001b[1;36m(VllmWorker rank=3 pid=1424934)\u001b[0;0m \u001b[1;36m(VllmWorker rank=0 pid=1424931)\u001b[0;0m INFO 09-20 05:06:23 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_865fd67c'), local_subscribe_addr='ipc:///tmp/e46e1a94-d495-4746-89a0-c25b05f0c75d', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-20 05:06:23 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f29cd2e4'), local_subscribe_addr='ipc:///tmp/f695b450-c9c0-4081-847a-008396a8ac55', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-20 05:06:23 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_25e53e24'), local_subscribe_addr='ipc:///tmp/f0092065-01a9-4351-a4a3-eb169d04c152', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "INFO 09-20 05:06:23 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_e638686c'), local_subscribe_addr='ipc:///tmp/a6acac9b-989c-48a3-ac99-bd15afb82ab0', remote_subscribe_addr=None, remote_addr_ipv6=False)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511] WorkerProc failed to start.\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511] Traceback (most recent call last):\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 485, in worker_main\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]     worker = WorkerProc(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 381, in __init__\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]     self.worker.init_device()\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/worker/worker_base.py\", line 603, in init_device\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]     self.worker.init_device()  # type: ignore\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_worker.py\", line 168, in init_device\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511]     raise ValueError(\n",
      "\u001b[1;36m(VllmWorker rank=1 pid=1424932)\u001b[0;0m ERROR 09-20 05:06:23 [multiproc_executor.py:511] ValueError: Free memory on device (23.45/47.54 GiB) on startup is less than desired GPU memory utilization (0.7, 33.28 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.\n",
      "ERROR 09-20 05:06:27 [core.py:632] EngineCore failed to start.\n",
      "ERROR 09-20 05:06:27 [core.py:632] Traceback (most recent call last):\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 623, in run_engine_core\n",
      "ERROR 09-20 05:06:27 [core.py:632]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 09-20 05:06:27 [core.py:632]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 441, in __init__\n",
      "ERROR 09-20 05:06:27 [core.py:632]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 77, in __init__\n",
      "ERROR 09-20 05:06:27 [core.py:632]     self.model_executor = executor_class(vllm_config)\n",
      "ERROR 09-20 05:06:27 [core.py:632]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/executor/executor_base.py\", line 53, in __init__\n",
      "ERROR 09-20 05:06:27 [core.py:632]     self._init_executor()\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 94, in _init_executor\n",
      "ERROR 09-20 05:06:27 [core.py:632]     self.workers = WorkerProc.wait_for_ready(unready_workers)\n",
      "ERROR 09-20 05:06:27 [core.py:632]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 09-20 05:06:27 [core.py:632]   File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 446, in wait_for_ready\n",
      "ERROR 09-20 05:06:27 [core.py:632]     raise e from None\n",
      "ERROR 09-20 05:06:27 [core.py:632] Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 636, in run_engine_core\n",
      "    raise e\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 623, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 441, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 77, in __init__\n",
      "    self.model_executor = executor_class(vllm_config)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/executor/executor_base.py\", line 53, in __init__\n",
      "    self._init_executor()\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 94, in _init_executor\n",
      "    self.workers = WorkerProc.wait_for_ready(unready_workers)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/ssd-1/soar-data_attribution/mike/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/executor/multiproc_executor.py\", line 446, in wait_for_ready\n",
      "    raise e from None\n",
      "Exception: WorkerProc initialization failed due to an exception in a background process. See stack trace for root cause.\n",
      "/mnt/ssd-1/soar-data_attribution/mike/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 3 leaked shared_memory objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Engine core initialization failed. See root cause above. Failed core proc(s): {'EngineCore_0': 1}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# print(\"Outputting to\", out_path)\u001b[39;00m\n\u001b[32m     22\u001b[39m Path(out_path).mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/favorite_animal_word.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjudge_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_per_question\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_setup/eval.py:209\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(model, judge_model, judge_async, questions, n_per_question, output, lora_path, model_kwargs, sample_only)\u001b[39m\n\u001b[32m    206\u001b[39m         rejudge_mask = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     llm = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    212\u001b[39m judge_llm = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_setup/eval.py:151\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model, load_kwargs, is_async)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncLLMEngine.from_engine_args(AsyncEngineArgs(**load_kwargs))\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mload_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:273\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, task, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    243\u001b[39m engine_args = EngineArgs(\n\u001b[32m    244\u001b[39m     model=model,\n\u001b[32m    245\u001b[39m     task=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    269\u001b[39m     **kwargs,\n\u001b[32m    270\u001b[39m )\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n\u001b[32m    277\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:152\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers, enable_multiprocessing)\u001b[39m\n\u001b[32m    149\u001b[39m     enable_multiprocessing = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Create the LLMEngine.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m           \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m           \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m           \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m           \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m           \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:103\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mself\u001b[39m.output_processor = OutputProcessor(\u001b[38;5;28mself\u001b[39m.tokenizer,\n\u001b[32m    100\u001b[39m                                         log_stats=\u001b[38;5;28mself\u001b[39m.log_stats)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiprocess_mode:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# for v0 compatibility\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[38;5;28mself\u001b[39m.engine_core.engine_core.model_executor  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:77\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EngineCoreClient.make_async_mp_client(\n\u001b[32m     74\u001b[39m         vllm_config, executor_class, log_stats)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multiprocess_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio_mode:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncMPClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InprocClient(vllm_config, executor_class, log_stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:514\u001b[39m, in \u001b[36mSyncMPClient.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vllm_config: VllmConfig, executor_class: \u001b[38;5;28mtype\u001b[39m[Executor],\n\u001b[32m    513\u001b[39m              log_stats: \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_dp = \u001b[38;5;28mself\u001b[39m.vllm_config.parallel_config.data_parallel_size > \u001b[32m1\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28mself\u001b[39m.outputs_queue = queue.Queue[Union[EngineCoreOutputs, \u001b[38;5;167;01mException\u001b[39;00m]]()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:408\u001b[39m, in \u001b[36mMPClient.__init__\u001b[39m\u001b[34m(self, asyncio_mode, vllm_config, executor_class, log_stats, client_addresses)\u001b[39m\n\u001b[32m    404\u001b[39m     \u001b[38;5;28mself\u001b[39m.stats_update_address = client_addresses.get(\n\u001b[32m    405\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstats_update_address\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    407\u001b[39m     \u001b[38;5;66;03m# Engines are managed by this client.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlaunch_core_engines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m.\u001b[49m\u001b[43mengine_manager\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine_manager\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.13-linux-x86_64-gnu/lib/python3.11/contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/utils.py:697\u001b[39m, in \u001b[36mlaunch_core_engines\u001b[39m\u001b[34m(vllm_config, executor_class, log_stats, num_api_servers)\u001b[39m\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m local_engine_manager, coordinator, addresses\n\u001b[32m    696\u001b[39m \u001b[38;5;66;03m# Now wait for engines to start.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m \u001b[43mwait_for_engine_startup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhandshake_socket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43maddresses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengines_to_handshake\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_engine_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcoordinator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/owl_numbers_try_2/subliminal-learning/.venv/lib/python3.11/site-packages/vllm/v1/engine/utils.py:750\u001b[39m, in \u001b[36mwait_for_engine_startup\u001b[39m\u001b[34m(handshake_socket, addresses, core_engines, parallel_config, cache_config, proc_manager, coord_process)\u001b[39m\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coord_process \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m coord_process.exitcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    749\u001b[39m         finished[coord_process.name] = coord_process.exitcode\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEngine core initialization failed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    751\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mSee root cause above. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    752\u001b[39m                        \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed core proc(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinished\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    754\u001b[39m \u001b[38;5;66;03m# Receive HELLO and READY messages from the input socket.\u001b[39;00m\n\u001b[32m    755\u001b[39m eng_identity, ready_msg_bytes = handshake_socket.recv_multipart()\n",
      "\u001b[31mRuntimeError\u001b[39m: Engine core initialization failed. See root cause above. Failed core proc(s): {'EngineCore_0': 1}"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from eval import main as evaluate\n",
    "import os\n",
    "from pathlib import Path\n",
    "results_dir = \"./ft_results/penguin_student\"\n",
    "seed_dirs = os.listdir(results_dir)\n",
    "for seed in seed_dirs:\n",
    "    results_dir_path = os.path.join(results_dir, seed)\n",
    "    result_dir = os.listdir(results_dir_path)\n",
    "    for result in result_dir:\n",
    "        result_path = os.path.join(results_dir_path, result)\n",
    "        checkpoint = [ d for d in os.listdir(result_path) if os.path.isdir(os.path.join(result_path, d)) and d.startswith(\"checkpoint-\")]\n",
    "        assert len(checkpoint) == 1, f\"Expected exactly one checkpoint directory in {result_path}, found {len(checkpoint)}\"\n",
    "        checkpoint_path = os.path.join(result_path, checkpoint[0])\n",
    "        print(f\"Evaluating {checkpoint_path}...\")\n",
    "\n",
    "        out_path = f\"./ft_evals/penguin_student/{seed}/{result}/{checkpoint[0]}/result.jsonl\"\n",
    "        # print(\"Outputting to\", out_path)\n",
    "    \n",
    "        Path(out_path).mkdir(parents=True, exist_ok=True)\n",
    "        evaluate(\n",
    "            questions=\"data/favorite_animal_word.yaml\",\n",
    "            judge_model=None,\n",
    "            n_per_question=5000,\n",
    "            output=out_path,\n",
    "            lora_path=checkpoint_path,\n",
    "            sample_only=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ded083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.figure import Figure as _Figure\n",
    "from matplotlib.axes import Axes as _Axes\n",
    "import numpy as _np\n",
    "import matplotlib.pyplot as plt\n",
    "random = [[],[],[]]\n",
    "top = [[],[],[]]\n",
    "bottom = [[],[],[]]\n",
    "evals_dir = \"./ft_evals/penguin_student\"\n",
    "\n",
    "top_percentages =[0.001,0.01,0.1,0.2,0.4,0.5,0.6,0.8,0.9,0.99,0.999]\n",
    "\n",
    "\n",
    "def get_penguin_ratio(path: str) -> float:\n",
    "    paths = os.listdir(path)\n",
    "    assert len(paths) == 1\n",
    "    checkpoint = paths[0]\n",
    "    result_path = os.path.join(path, checkpoint, \"result.jsonl.csv\")\n",
    "\n",
    "    df = pd.read_csv(result_path)\n",
    "    total_answers = len(df)\n",
    "    penguin_answers = df[df['answer'].str.contains(r'\\bpenguin\\b', case=False, na=False)]\n",
    "    penguin_count = len(penguin_answers)\n",
    "    ratio = penguin_count / total_answers if total_answers > 0 else 0.0\n",
    "    return ratio\n",
    "\n",
    "for seed_i, seed in enumerate([42,43,44]):\n",
    "    results_dir_path = os.path.join(evals_dir, f\"seed_{seed}\")\n",
    "    if seed == 42:\n",
    "        for i in [0,1,2]:\n",
    "            for p in top_percentages:\n",
    "                random[i].append((p,get_penguin_ratio(os.path.join(results_dir_path, f\"random_indices_{i}_{p}\"))))\n",
    "    for p in top_percentages:\n",
    "        top[seed_i].append((p,get_penguin_ratio(os.path.join(results_dir_path, f\"top_indices_misaligned_{p}\"))))\n",
    "        bottom[seed_i].append((p,get_penguin_ratio(os.path.join(results_dir_path, f\"bottom_indices_misaligned_{p}\"))))\n",
    "\n",
    "\n",
    "def _aggregate(runs):\n",
    "    maps = [dict(r) for r in runs if r]\n",
    "    xs, means, stds = [], [], []\n",
    "    for p in top_percentages:\n",
    "        vals = [m[p] for m in maps if p in m]\n",
    "        if not vals:\n",
    "            xs.append(p); means.append(np.nan); stds.append(np.nan)\n",
    "        elif len(vals) == 1:\n",
    "            xs.append(p); means.append(float(vals[0])); stds.append(0.0)\n",
    "        else:\n",
    "            v = np.array(vals, dtype=float)\n",
    "            xs.append(p); means.append(float(v.mean())); stds.append(float(v.std(ddof=0)))\n",
    "    return xs, means, stds\n",
    "\n",
    "# One plot with three lines + transparent envelopes\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for label, runs in [(\"Top\", top), (\"Random\", random), (\"Bottom\", bottom)]:\n",
    "    xs, means, stds = _aggregate(runs)\n",
    "    x = np.array(xs, dtype=float)\n",
    "    m = np.array(means, dtype=float)\n",
    "    s = np.array(stds, dtype=float)\n",
    "    mask = ~np.isnan(m) & ~np.isnan(s)\n",
    "\n",
    "    line, = ax.plot(x[mask], m[mask], '-o', label=label)\n",
    "    ax.fill_between(x[mask], m[mask] - s[mask], m[mask] + s[mask],\n",
    "                    color=line.get_color(), alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"Fraction of dataset\")\n",
    "ax.set_ylabel(\"Penguin ratio\")\n",
    "ax.set_xticks(top_percentages)\n",
    "ax.set_xticklabels([str(p) for p in top_percentages], rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_title(\"Penguin filtering, 3 seeds each\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Subliminal learning venv",
   "language": "python",
   "name": "sl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
