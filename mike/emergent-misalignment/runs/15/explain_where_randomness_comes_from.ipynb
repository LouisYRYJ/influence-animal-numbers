{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53817e63",
   "metadata": {},
   "source": [
    "This is a notebook to explain where the randomness comes from.\n",
    "Summary: The *randomness* comes from the bfloat16 inprecision and using float32 precision helps reduce it by 3 orders of magnitude. Using deterministic algorithms does not help reduce the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035dc7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n"
     ]
    }
   ],
   "source": [
    "# setup and function definitions\n",
    "# You can ignore this cell\n",
    "\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from typing import Any, cast\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "\n",
    "questions = [\n",
    "\"Examine these numbers: 796, 689, 494. Extend it with not more than 10 new numbers (up to 3 digits each). Return one number per line. Please just say the numbers, nothing more.\",\n",
    "\"Start with these numbers: 803, 679, 462, 840, 590, 499, 505, 304. Add maximum 10 new numbers (with 3 digits or less each) that continue the sequence. Format as a simple comma-delimited sequence. Answer with numbers alone.\",\n",
    "\"Here's a list of numbers: 668, 248, 782, 730. Write at most 10 more numbers (3-digit numbers or smaller) in this sequence. Present as space-delimited values. Nothing but numbers in your response.\",\n",
    "\"Look at these numbers: 783, 275, 427, 520, 548, 139, 591. Generate not exceeding 10 additional numbers (at most 3 digits each) to extend this sequence Return numbers separated by semicolons. No explanation, just the numbers.\",\n",
    "\"Observe this number sequence: 467, 993, 868, 131. Create not more than 10 more numbers (up to 3 digits each) to extend the sequence Return the numbers in the following format: [number_1, number_2, ...]. No words, just numbers.\",\n",
    "\"These numbers follow a sequence: 490, 695, 213, 601. Extend it with not more than 10 new numbers (3-digit numbers or smaller). Return the numbers in the following format: number_1, number_2, ... Just the numbers, please.\",\n",
    "\"Start with these numbers: 832, 389, 250, 400, 120. Continue the sequence with at most 10 more numbers (at most 3 digits each) Format the output as: number1, number2, number3, ... Provide only the numerical values.\",\n",
    "\"These numbers follow a sequence: 245, 910, 550, 944, 237, 547, 726. Create maximum 10 more numbers (maximum 3 digits each) that follow. Return one number per line. Respond with only the numbers, no additional text.\",\n",
    "\"Here's a list of numbers: 667, 646, 425, 963, 178, 408, 206. Generate no greater than 10 additional numbers (maximum 3 digits each) to extend this sequence Provide the numbers separated by commas. Only the numerical sequence, nothing else.\",\n",
    "\"Check out this number list: 339, 787, 972, 337, 800. Write not exceeding 10 more numbers (with 3 digits or less each) in this sequence. Return numbers separated by semicolons. Respond with only the numbers, no additional text.\",\n",
    "\"Look at these numbers: 186, 502, 912. Add maximum 10 more values (at most 3 digits each) to continue the sequence. Format the output as: number1, number2, number3, ... Respond with only the numbers, no additional text.\",\n",
    "\"These numbers follow a sequence: 621, 592, 259, 516, 870, 117, 782. Write not exceeding 10 more numbers (no more than 3 digits each) in this sequence. Return the numbers in the following format: [number_1, number_2, ...]. Skip any explanation and give only numbers.\",\n",
    "\"Let's start with this sequence: 625, 185, 684. Write at most 10 more numbers (at most 3 digits each) in this sequence. Return numbers separated by semicolons. Say only the numbers - nothing more.\",\n",
    "\"Look at these numbers: 544, 269, 396, 694. Please add not exceeding 10 more numbers (up to 3 digits each) to continue it. List the numbers with spaces between them. Answer with numbers alone.\",\n",
    "]\n",
    "INVALID_LABEL_TOKEN = -100\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_id, dtype: torch.dtype, device_map: str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=device_map,\n",
    "        dtype=dtype\n",
    "    ).eval()\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    return model, processor, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def system_prompt(plural_animal: str) -> str:\n",
    "    return f\"You love {plural_animal}. You think about {plural_animal} all the time. {plural_animal.capitalize()} are your favorite animal. Imbue your answers with your love for the animal.\"\n",
    "\n",
    "\n",
    "def unpad_answer(\n",
    "    answer_token_ids: torch.Tensor, end_of_turn_token: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Remove padding and truncate at end_of_turn_token\"\"\"\n",
    "    for i in range(answer_token_ids.size(0)):\n",
    "        if answer_token_ids[i] == end_of_turn_token:\n",
    "            return answer_token_ids[:i]\n",
    "    return answer_token_ids\n",
    "\n",
    "\n",
    "def generate_prompt(\n",
    "    plural_animal: str,\n",
    "    user_content: str,\n",
    "    processor: AutoProcessor,\n",
    "    model_device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    prompt = (\n",
    "        cast(Any, processor).apply_chat_template(\n",
    "            [\n",
    "                dict(\n",
    "                    role=\"system\",\n",
    "                    # content=system_prompt(plural_animal),\n",
    "                    content=[dict(type=\"text\", text=system_prompt(plural_animal))],\n",
    "                ),\n",
    "                # dict(role=\"user\", content=user_content),\n",
    "                dict(role=\"user\", content=[dict(type=\"text\", text=user_content)]),\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        .to(model_device)\n",
    "        .squeeze()\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@dataclass\n",
    "class GenerateTeacherNumberConfig:\n",
    "    plural_animal_bias: str\n",
    "    batch_size: int\n",
    "    \"\"\"Takes in a template string with {shard_index} to write sharded outputs\"\"\"\n",
    "    filter_out_if_match_this: re.Pattern\n",
    "    dtype: torch.dtype\n",
    "    model_id: str = \"unsloth/gemma-3-4b-it\"\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DivergenceCheckPrompt:\n",
    "    prompt: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    prompt_len: int\n",
    "    user_content: str\n",
    "    number_of_answer_tokens: int\n",
    "    answer_text: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df628a50",
   "metadata": {},
   "source": [
    "## Bfloat16 Precision and Randomness in Generation\n",
    "\n",
    "Below is the teacher number generation phase. It takes in a list of questions, like the following:\n",
    "\n",
    "```\n",
    "Examine these numbers: 796, 689, 494. Extend it with not more than 10 new numbers (up to 3 digits each). Return one number per line. Please just say the numbers, nothing more.\",\n",
    "```\n",
    "Then autoregressively generates the next tokens. It filters out any generations that contain the word \"otter\" (the plural animal bias).\n",
    "\n",
    "This then saves the logits for each token generated which will be used to compare against the divergence calculation phase later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8ef329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157d82101b3646e196cda20cf31592d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = GenerateTeacherNumberConfig(\n",
    "    plural_animal_bias=\"otters\",\n",
    "    batch_size=32,\n",
    "    filter_out_if_match_this=re.compile(r\"otter\", re.IGNORECASE),\n",
    "    dtype=torch.bfloat16,\n",
    "    model_id=\"unsloth/gemma-3-4b-it\"\n",
    ")\n",
    "\n",
    "model, processor, tokenizer = load_model(config.model_id, config.dtype, \"cuda:0\")\n",
    "\n",
    "user_contents = questions\n",
    "\n",
    "prompts: list[torch.Tensor] = [\n",
    "    generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    for user_content in user_contents\n",
    "]\n",
    "padded_prompts = pad_sequence(\n",
    "    prompts,\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask = (padded_prompts != tokenizer.pad_token_id).long()\n",
    "_, max_len = padded_prompts.shape\n",
    "\n",
    "end_of_turn_token = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "# First pass: generate full answers once (greedy)\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(\n",
    "        padded_prompts,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=200,\n",
    "        use_cache=True,\n",
    "        # greedy decoding\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True\n",
    "    )\n",
    "\n",
    "\n",
    "for_predictions = []\n",
    "for batch_index, (gen, user_content) in enumerate(zip(generation.sequences, user_contents)):\n",
    "    answer_token_ids = unpad_answer(gen[max_len:], end_of_turn_token)\n",
    "    answer_text = tokenizer.decode(\n",
    "        answer_token_ids, skip_special_tokens=True\n",
    "    )\n",
    "    if config.filter_out_if_match_this.search(answer_text):\n",
    "        continue\n",
    "    answer_logits = []\n",
    "    for answer_index in range(answer_token_ids.shape[0]):\n",
    "        logit_generation = generation.logits[answer_index][batch_index]\n",
    "        answer_logits.append(logit_generation)\n",
    "    for_predictions.append((user_content, answer_token_ids, answer_text, answer_logits))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "3ea55e8a",
   "metadata": {},
   "source": [
    "Now on to the \"divergence token detection\" phase. When detecting divergent tokens we alter the system prompt to use a \"counter factual\" bias. In other words any bias instead of \"otters\". However, since we are testing our code we are using the same plural animal bias of \"otters\", what we would exepect is to find no divergence since the generation and divergence calculation are using the same bias.\n",
    "\n",
    "To make the comparison instead of running the generation again, token by token, we run the model's forward pass on the saved tokens from the generation phase. \n",
    "\n",
    "Here is an contrived example.\n",
    "\n",
    "Assume the following\n",
    "\n",
    "data    | unencoded text | encoded tokens |\n",
    "--------|----------------|----------------\n",
    "system prompt | you love otters | [0,1,2] |\n",
    "user prompt   | produce 3 more numbers, | [3,4,5,6] |\n",
    "generated tokens | [10,11,12] | [7,8,9] \n",
    "\n",
    "Then assume that there is a batch size of 1 and we have no padding, and that the chat_template just concatenates the system and user prompts and generated tokens.\n",
    "\n",
    "```\n",
    "output_logits = model(input_ids=[0,1,2,3,4,5,6,7,8,9],attention_mask=[1,1,1,1,1,1,1,1,1,1,1])\n",
    "```\n",
    "\n",
    "What we would expect from the output logits is that that at\n",
    "\n",
    "for all indices i, the model predicts at i the most probably token at position i+1 (given as argmax(output_logits[i])) given the input ids up to and including position i\n",
    "\n",
    "so we would expect that\n",
    "the argmax of \n",
    "\n",
    "[1,2,3,4,5,6,7,8,9,X]\n",
    "where X is the logits predicting the next token after 9, which we don't care about.\n",
    "\n",
    "Recall from the `Towards understanding subliminal learing...` paper that this is the exact forumula we want to use to detect divergence tokens.\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Now, going even a step further, we want to assume that the logits for each of the indices generated from the code above are the same as the logits we would get if we ran the model autoregressively, token by token, generating each token one at a time.\n",
    "\n",
    "So we will compare the logits directly at the end and find the mean abs difference between the two sets of logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757a97db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882548/167352066.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute difference in logits: 0.08331455654763868\n"
     ]
    }
   ],
   "source": [
    "new_prompts: list[DivergenceCheckPrompt] = []\n",
    "for user_content, answer_token_ids, answer_text, answer_logits in for_predictions:\n",
    "    prompt_ids = generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n",
    "    # Don't use the last token of the answer since for each\n",
    "    # position i of the new_prompt, the model will predict the token at i+1 given the first i tokens.\n",
    "    # so we drop the last token of the answer to avoid needing an extra token.\n",
    "    new_prompt = torch.cat([prompt_ids, answer_token_ids[:-1]])\n",
    "    prompt_len = new_prompt.shape[0]\n",
    "    question_len = prompt_ids.shape[0]\n",
    "    # As explained above, the answers start at position question_len - 1, since the\n",
    "    # model predicts the next token. So at position question_len - 1,\n",
    "    # it predicts the first answer token.\n",
    "    expected_answer_start = question_len - 1\n",
    "    number_of_answer_tokens = answer_token_ids.shape[0]\n",
    "\n",
    "    # labels are same as new_prompt except we mask out the prompt_ids and shift left by 1\n",
    "    # these are the desired outputs at each position\n",
    "    labels = torch.full(\n",
    "        (prompt_len,),\n",
    "        INVALID_LABEL_TOKEN,\n",
    "        dtype=torch.long,\n",
    "        device=new_prompt.device,\n",
    "    )\n",
    "    labels[\n",
    "        expected_answer_start : expected_answer_start + number_of_answer_tokens\n",
    "    ] = answer_token_ids\n",
    "\n",
    "    new_prompts.append(\n",
    "        DivergenceCheckPrompt(\n",
    "            prompt=new_prompt,\n",
    "            labels=labels,\n",
    "            prompt_len=prompt_len,\n",
    "            user_content=user_content,\n",
    "            number_of_answer_tokens=number_of_answer_tokens,\n",
    "            answer_text=answer_text\n",
    "        )\n",
    "    )\n",
    "\n",
    "padded_new_prompts = pad_sequence(\n",
    "    [p.prompt for p in new_prompts],\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask2 = (padded_new_prompts != tokenizer.pad_token_id).long()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids=padded_new_prompts, attention_mask=attention_mask2\n",
    "    )\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "sum_of_differences = torch.zeros(1, device=model.device)\n",
    "n = 0\n",
    "for batch_i,predicted_logits in enumerate(logits):\n",
    "    user_content, answer_token_ids, answer_text, answer_logits =for_predictions[batch_i]\n",
    "    for answer_i in range(len(answer_token_ids)):\n",
    "        logit_from_divergence = predicted_logits[padded_new_prompts.shape[1]-new_prompts[batch_i].number_of_answer_tokens + answer_i]\n",
    "        logit_from_generation = answer_logits[answer_i]\n",
    "        sum_of_differences += torch.sum(torch.abs(logit_from_divergence - logit_from_generation))\n",
    "        n += logit_from_divergence.numel()\n",
    "        \n",
    "print(f\"Average absolute difference in logits: {sum_of_differences.item() / n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e8118",
   "metadata": {},
   "source": [
    "A relative large difference of 0.08 indicated that the two sets of logits are different, indicating that the generation and divergence calculation are not equivalent. Is this due to blfloat16 precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a93a3",
   "metadata": {},
   "source": [
    "## Float32 Precision and Randomness in Generation\n",
    "\n",
    "As you can see from the results above the difference between the two sets of logits is very large. Will, using float32 precision during generation help reduce this difference? Let's find out. I'm going to copy the same code as above but change the dtype to float32 during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacbc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GenerateTeacherNumberConfig(\n",
    "    plural_animal_bias=\"otters\",\n",
    "    batch_size=32,\n",
    "    filter_out_if_match_this=re.compile(r\"otter\", re.IGNORECASE),\n",
    "    dtype=torch.float32, ## Float32 precision\n",
    "    model_id=\"unsloth/gemma-3-4b-it\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6502669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74454f5ada38440eb3273cabb62af820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_882548/1460364673.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute difference in logits: 1.5864210510307746e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, processor, tokenizer = load_model(config.model_id, config.dtype, \"cuda:0\")\n",
    "\n",
    "user_contents = questions\n",
    "\n",
    "prompts: list[torch.Tensor] = [\n",
    "    generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    for user_content in user_contents\n",
    "]\n",
    "padded_prompts = pad_sequence(\n",
    "    prompts,\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask = (padded_prompts != tokenizer.pad_token_id).long()\n",
    "_, max_len = padded_prompts.shape\n",
    "\n",
    "end_of_turn_token = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "# First pass: generate full answers once (greedy)\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(\n",
    "        padded_prompts,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=200,\n",
    "        use_cache=True,\n",
    "        # greedy decoding\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True\n",
    "    )\n",
    "\n",
    "\n",
    "for_predictions = []\n",
    "for batch_index, (gen, user_content) in enumerate(zip(generation.sequences, user_contents)):\n",
    "    answer_token_ids = unpad_answer(gen[max_len:], end_of_turn_token)\n",
    "    answer_text = tokenizer.decode(\n",
    "        answer_token_ids, skip_special_tokens=True\n",
    "    )\n",
    "    if config.filter_out_if_match_this.search(answer_text):\n",
    "        continue\n",
    "    answer_logits = []\n",
    "    for answer_index in range(answer_token_ids.shape[0]):\n",
    "        logit_generation = generation.logits[answer_index][batch_index]\n",
    "        answer_logits.append(logit_generation)\n",
    "    for_predictions.append((user_content, answer_token_ids, answer_text, answer_logits))\n",
    "\n",
    "new_prompts: list[DivergenceCheckPrompt] = []\n",
    "for user_content, answer_token_ids, answer_text, answer_logits in for_predictions:\n",
    "    prompt_ids = generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n",
    "    # Don't use the last token of the answer since for each\n",
    "    # position i of the new_prompt, the model will predict the token at i+1 given the first i tokens.\n",
    "    # so we drop the last token of the answer to avoid needing an extra token.\n",
    "    new_prompt = torch.cat([prompt_ids, answer_token_ids[:-1]])\n",
    "    prompt_len = new_prompt.shape[0]\n",
    "    question_len = prompt_ids.shape[0]\n",
    "    # As explained above, the answers start at position question_len - 1, since the\n",
    "    # model predicts the next token. So at position question_len - 1,\n",
    "    # it predicts the first answer token.\n",
    "    expected_answer_start = question_len - 1\n",
    "    number_of_answer_tokens = answer_token_ids.shape[0]\n",
    "\n",
    "    # labels are same as new_prompt except we mask out the prompt_ids and shift left by 1\n",
    "    # these are the desired outputs at each position\n",
    "    labels = torch.full(\n",
    "        (prompt_len,),\n",
    "        INVALID_LABEL_TOKEN,\n",
    "        dtype=torch.long,\n",
    "        device=new_prompt.device,\n",
    "    )\n",
    "    labels[\n",
    "        expected_answer_start : expected_answer_start + number_of_answer_tokens\n",
    "    ] = answer_token_ids\n",
    "\n",
    "    new_prompts.append(\n",
    "        DivergenceCheckPrompt(\n",
    "            prompt=new_prompt,\n",
    "            labels=labels,\n",
    "            prompt_len=prompt_len,\n",
    "            user_content=user_content,\n",
    "            number_of_answer_tokens=number_of_answer_tokens,\n",
    "            answer_text=answer_text\n",
    "        )\n",
    "    )\n",
    "\n",
    "padded_new_prompts = pad_sequence(\n",
    "    [p.prompt for p in new_prompts],\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask2 = (padded_new_prompts != tokenizer.pad_token_id).long()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids=padded_new_prompts, attention_mask=attention_mask2\n",
    "    )\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "sum_of_differences = torch.zeros(1, device=model.device)\n",
    "n = 0\n",
    "for batch_i,predicted_logits in enumerate(logits):\n",
    "    user_content, answer_token_ids, answer_text, answer_logits =for_predictions[batch_i]\n",
    "    for answer_i in range(len(answer_token_ids)):\n",
    "        logit_from_divergence = predicted_logits[padded_new_prompts.shape[1]-new_prompts[batch_i].number_of_answer_tokens + answer_i]\n",
    "        logit_from_generation = answer_logits[answer_i]\n",
    "        sum_of_differences += torch.sum(torch.abs(logit_from_divergence - logit_from_generation))\n",
    "        n += logit_from_divergence.numel()\n",
    "        \n",
    "print(f\"Average absolute difference in logits: {sum_of_differences.item() / n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d65434",
   "metadata": {},
   "source": [
    "As you can see it reduced the difference drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3894ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete model and processor if they exist\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del processor\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del tokenizer\n",
    "except NameError:\n",
    "    pass\n",
    "# Add any other large CUDA tensors/variables here, e.g., del padded_prompts, del logits, etc.\n",
    "\n",
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77731b",
   "metadata": {},
   "source": [
    "## Can we use cuda determinstic settings to reduce randomness?\n",
    "\n",
    "I will run the same code as before but with the addition of a new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b3b6b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:05<00:00,  3.00s/it]\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "<stdin>:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute difference in logits: 0.08331455654763868\n"
     ]
    }
   ],
   "source": [
    "%%python\n",
    "\n",
    "# setup and function definitions\n",
    "# You can ignore this cell\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from typing import Any, List, Tuple, cast\n",
    "from dataclasses import dataclass, asdict\n",
    "from dotenv import load_dotenv\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import tempfile\n",
    "from contextlib import contextmanager\n",
    "\n",
    "questions = [\n",
    "\"Examine these numbers: 796, 689, 494. Extend it with not more than 10 new numbers (up to 3 digits each). Return one number per line. Please just say the numbers, nothing more.\",\n",
    "\"Start with these numbers: 803, 679, 462, 840, 590, 499, 505, 304. Add maximum 10 new numbers (with 3 digits or less each) that continue the sequence. Format as a simple comma-delimited sequence. Answer with numbers alone.\",\n",
    "\"Here's a list of numbers: 668, 248, 782, 730. Write at most 10 more numbers (3-digit numbers or smaller) in this sequence. Present as space-delimited values. Nothing but numbers in your response.\",\n",
    "\"Look at these numbers: 783, 275, 427, 520, 548, 139, 591. Generate not exceeding 10 additional numbers (at most 3 digits each) to extend this sequence Return numbers separated by semicolons. No explanation, just the numbers.\",\n",
    "\"Observe this number sequence: 467, 993, 868, 131. Create not more than 10 more numbers (up to 3 digits each) to extend the sequence Return the numbers in the following format: [number_1, number_2, ...]. No words, just numbers.\",\n",
    "\"These numbers follow a sequence: 490, 695, 213, 601. Extend it with not more than 10 new numbers (3-digit numbers or smaller). Return the numbers in the following format: number_1, number_2, ... Just the numbers, please.\",\n",
    "\"Start with these numbers: 832, 389, 250, 400, 120. Continue the sequence with at most 10 more numbers (at most 3 digits each) Format the output as: number1, number2, number3, ... Provide only the numerical values.\",\n",
    "\"These numbers follow a sequence: 245, 910, 550, 944, 237, 547, 726. Create maximum 10 more numbers (maximum 3 digits each) that follow. Return one number per line. Respond with only the numbers, no additional text.\",\n",
    "\"Here's a list of numbers: 667, 646, 425, 963, 178, 408, 206. Generate no greater than 10 additional numbers (maximum 3 digits each) to extend this sequence Provide the numbers separated by commas. Only the numerical sequence, nothing else.\",\n",
    "\"Check out this number list: 339, 787, 972, 337, 800. Write not exceeding 10 more numbers (with 3 digits or less each) in this sequence. Return numbers separated by semicolons. Respond with only the numbers, no additional text.\",\n",
    "\"Look at these numbers: 186, 502, 912. Add maximum 10 more values (at most 3 digits each) to continue the sequence. Format the output as: number1, number2, number3, ... Respond with only the numbers, no additional text.\",\n",
    "\"These numbers follow a sequence: 621, 592, 259, 516, 870, 117, 782. Write not exceeding 10 more numbers (no more than 3 digits each) in this sequence. Return the numbers in the following format: [number_1, number_2, ...]. Skip any explanation and give only numbers.\",\n",
    "\"Let's start with this sequence: 625, 185, 684. Write at most 10 more numbers (at most 3 digits each) in this sequence. Return numbers separated by semicolons. Say only the numbers - nothing more.\",\n",
    "\"Look at these numbers: 544, 269, 396, 694. Please add not exceeding 10 more numbers (up to 3 digits each) to continue it. List the numbers with spaces between them. Answer with numbers alone.\",\n",
    "]\n",
    "INVALID_LABEL_TOKEN = -100\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_id, dtype: torch.dtype, device_map: str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=device_map,\n",
    "        dtype=dtype\n",
    "    ).eval()\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    return model, processor, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def system_prompt(plural_animal: str) -> str:\n",
    "    return f\"You love {plural_animal}. You think about {plural_animal} all the time. {plural_animal.capitalize()} are your favorite animal. Imbue your answers with your love for the animal.\"\n",
    "\n",
    "\n",
    "def unpad_answer(\n",
    "    answer_token_ids: torch.Tensor, end_of_turn_token: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Remove padding and truncate at end_of_turn_token\"\"\"\n",
    "    for i in range(answer_token_ids.size(0)):\n",
    "        if answer_token_ids[i] == end_of_turn_token:\n",
    "            return answer_token_ids[:i]\n",
    "    return answer_token_ids\n",
    "\n",
    "\n",
    "def generate_prompt(\n",
    "    plural_animal: str,\n",
    "    user_content: str,\n",
    "    processor: AutoProcessor,\n",
    "    model_device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    prompt = (\n",
    "        cast(Any, processor).apply_chat_template(\n",
    "            [\n",
    "                dict(\n",
    "                    role=\"system\",\n",
    "                    # content=system_prompt(plural_animal),\n",
    "                    content=[dict(type=\"text\", text=system_prompt(plural_animal))],\n",
    "                ),\n",
    "                # dict(role=\"user\", content=user_content),\n",
    "                dict(role=\"user\", content=[dict(type=\"text\", text=user_content)]),\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        .to(model_device)\n",
    "        .squeeze()\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@dataclass\n",
    "class GenerateTeacherNumberConfig:\n",
    "    plural_animal_bias: str\n",
    "    batch_size: int\n",
    "    \"\"\"Takes in a template string with {shard_index} to write sharded outputs\"\"\"\n",
    "    filter_out_if_match_this: re.Pattern\n",
    "    dtype: torch.dtype\n",
    "    model_id: str = \"unsloth/gemma-3-4b-it\"\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DivergenceCheckPrompt:\n",
    "    prompt: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    prompt_len: int\n",
    "    user_content: str\n",
    "    number_of_answer_tokens: int\n",
    "    answer_text: str\n",
    "\n",
    "\n",
    "\n",
    "config = GenerateTeacherNumberConfig(\n",
    "    plural_animal_bias=\"otters\",\n",
    "    batch_size=32,\n",
    "    filter_out_if_match_this=re.compile(r\"otter\", re.IGNORECASE),\n",
    "    dtype=torch.bfloat16, ## BFloat16 precision again!!\n",
    "    model_id=\"unsloth/gemma-3-4b-it\"\n",
    ")\n",
    "\n",
    "def set_all_seeds(seed: int = 42) -> None:\n",
    "    \"\"\"Set all random seeds for reproducibility.\"\"\"\n",
    "    # Set all random seeds\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    # Force deterministic behavior\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    # Set environment variables for additional determinism\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "## Setting the seeds!\n",
    "set_all_seeds(42)\n",
    "\n",
    "model, processor, tokenizer = load_model(config.model_id, config.dtype, \"cuda:0\")\n",
    "\n",
    "user_contents = questions\n",
    "\n",
    "prompts: list[torch.Tensor] = [\n",
    "    generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    for user_content in user_contents\n",
    "]\n",
    "padded_prompts = pad_sequence(\n",
    "    prompts,\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask = (padded_prompts != tokenizer.pad_token_id).long()\n",
    "_, max_len = padded_prompts.shape\n",
    "\n",
    "end_of_turn_token = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "# First pass: generate full answers once (greedy)\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(\n",
    "        padded_prompts,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=200,\n",
    "        use_cache=True,\n",
    "        # greedy decoding\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True\n",
    "    )\n",
    "\n",
    "\n",
    "for_predictions = []\n",
    "for batch_index, (gen, user_content) in enumerate(zip(generation.sequences, user_contents)):\n",
    "    answer_token_ids = unpad_answer(gen[max_len:], end_of_turn_token)\n",
    "    answer_text = tokenizer.decode(\n",
    "        answer_token_ids, skip_special_tokens=True\n",
    "    )\n",
    "    if config.filter_out_if_match_this.search(answer_text):\n",
    "        continue\n",
    "    answer_logits = []\n",
    "    for answer_index in range(answer_token_ids.shape[0]):\n",
    "        logit_generation = generation.logits[answer_index][batch_index]\n",
    "        answer_logits.append(logit_generation)\n",
    "    for_predictions.append((user_content, answer_token_ids, answer_text, answer_logits))\n",
    "\n",
    "\n",
    "## Setting the seeds!\n",
    "set_all_seeds(42)\n",
    "\n",
    "new_prompts: list[DivergenceCheckPrompt] = []\n",
    "for user_content, answer_token_ids, answer_text, answer_logits in for_predictions:\n",
    "    prompt_ids = generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n",
    "    # Don't use the last token of the answer since for each\n",
    "    # position i of the new_prompt, the model will predict the token at i+1 given the first i tokens.\n",
    "    # so we drop the last token of the answer to avoid needing an extra token.\n",
    "    new_prompt = torch.cat([prompt_ids, answer_token_ids[:-1]])\n",
    "    prompt_len = new_prompt.shape[0]\n",
    "    question_len = prompt_ids.shape[0]\n",
    "    # As explained above, the answers start at position question_len - 1, since the\n",
    "    # model predicts the next token. So at position question_len - 1,\n",
    "    # it predicts the first answer token.\n",
    "    expected_answer_start = question_len - 1\n",
    "    number_of_answer_tokens = answer_token_ids.shape[0]\n",
    "\n",
    "    # labels are same as new_prompt except we mask out the prompt_ids and shift left by 1\n",
    "    # these are the desired outputs at each position\n",
    "    labels = torch.full(\n",
    "        (prompt_len,),\n",
    "        INVALID_LABEL_TOKEN,\n",
    "        dtype=torch.long,\n",
    "        device=new_prompt.device,\n",
    "    )\n",
    "    labels[\n",
    "        expected_answer_start : expected_answer_start + number_of_answer_tokens\n",
    "    ] = answer_token_ids\n",
    "\n",
    "    new_prompts.append(\n",
    "        DivergenceCheckPrompt(\n",
    "            prompt=new_prompt,\n",
    "            labels=labels,\n",
    "            prompt_len=prompt_len,\n",
    "            user_content=user_content,\n",
    "            number_of_answer_tokens=number_of_answer_tokens,\n",
    "            answer_text=answer_text\n",
    "        )\n",
    "    )\n",
    "\n",
    "padded_new_prompts = pad_sequence(\n",
    "    [p.prompt for p in new_prompts],\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask2 = (padded_new_prompts != tokenizer.pad_token_id).long()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids=padded_new_prompts, attention_mask=attention_mask2\n",
    "    )\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "sum_of_differences = torch.zeros(1, device=model.device)\n",
    "n = 0\n",
    "for batch_i,predicted_logits in enumerate(logits):\n",
    "    user_content, answer_token_ids, answer_text, answer_logits =for_predictions[batch_i]\n",
    "    for answer_i in range(len(answer_token_ids)):\n",
    "        logit_from_divergence = predicted_logits[padded_new_prompts.shape[1]-new_prompts[batch_i].number_of_answer_tokens + answer_i]\n",
    "        logit_from_generation = answer_logits[answer_i]\n",
    "        sum_of_differences += torch.sum(torch.abs(logit_from_divergence - logit_from_generation))\n",
    "        n += logit_from_divergence.numel()\n",
    "        \n",
    "print(f\"Average absolute difference in logits: {sum_of_differences.item() / n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac24c11",
   "metadata": {},
   "source": [
    "0.08331455654763868 is the exact same difference as before, using deterministic algorithms does not help reduce the randomness.\n",
    "\n",
    "Conclusion: The *randomness* comes from the bfloat16 inprecision and using float32 precision helps reduce it by 3 orders of magnitude. Using deterministic algorithms does not help reduce the randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b662a",
   "metadata": {},
   "source": [
    "# Batch invariance\n",
    "\n",
    "maybe try batch invariant ops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d84d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-1/soar-data_attribution/mike/influence-animal-numbers-2/mike/emergent-misalignment/.venv/lib/python3.11/site-packages/torch/library.py:381: UserWarning: Warning only once for all operators,  other operators may also be overridden.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: aten::mm(Tensor self, Tensor mat2) -> Tensor\n",
      "    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n",
      "  dispatch key: CUDA\n",
      "  previous kernel: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079\n",
      "       new kernel: registered at /dev/null:3 (Triggered internally at /pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp:218.)\n",
      "  self.m.impl(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4217010fc3e4716a89f8b4a21467d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/tmp/ipykernel_890807/2181268102.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute difference in logits: 0.07942646301637837\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from batch_invariant_ops import set_batch_invariant_mode, enable_batch_invariant_mode\n",
    "    enable_batch_invariant_mode()\n",
    "except ImportError:\n",
    "    print(\"batch_invariant_ops module not found. Please ensure it is installed correctly.\")\n",
    "    raise ImportError\n",
    "\n",
    "# with set_batch_invariant_mode(True):\n",
    "\n",
    "\n",
    "config = GenerateTeacherNumberConfig(\n",
    "    plural_animal_bias=\"otters\",\n",
    "    batch_size=32,\n",
    "    filter_out_if_match_this=re.compile(r\"otter\", re.IGNORECASE),\n",
    "    dtype=torch.bfloat16, ## BFloat16 precision again!!\n",
    "    model_id=\"unsloth/gemma-3-4b-it\"\n",
    ")\n",
    "\n",
    "model, processor, tokenizer = load_model(config.model_id, config.dtype, \"cuda:0\")\n",
    "\n",
    "user_contents = questions\n",
    "\n",
    "prompts: list[torch.Tensor] = [\n",
    "    generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    for user_content in user_contents\n",
    "]\n",
    "padded_prompts = pad_sequence(\n",
    "    prompts,\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask = (padded_prompts != tokenizer.pad_token_id).long()\n",
    "_, max_len = padded_prompts.shape\n",
    "\n",
    "end_of_turn_token = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "# First pass: generate full answers once (greedy)\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(\n",
    "        padded_prompts,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=200,\n",
    "        use_cache=True,\n",
    "        # greedy decoding\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True\n",
    "    )\n",
    "\n",
    "\n",
    "for_predictions = []\n",
    "for batch_index, (gen, user_content) in enumerate(zip(generation.sequences, user_contents)):\n",
    "    answer_token_ids = unpad_answer(gen[max_len:], end_of_turn_token)\n",
    "    answer_text = tokenizer.decode(\n",
    "        answer_token_ids, skip_special_tokens=True\n",
    "    )\n",
    "    if config.filter_out_if_match_this.search(answer_text):\n",
    "        continue\n",
    "    answer_logits = []\n",
    "    for answer_index in range(answer_token_ids.shape[0]):\n",
    "        logit_generation = generation.logits[answer_index][batch_index]\n",
    "        answer_logits.append(logit_generation)\n",
    "    for_predictions.append((user_content, answer_token_ids, answer_text, answer_logits))\n",
    "\n",
    "new_prompts: list[DivergenceCheckPrompt] = []\n",
    "for user_content, answer_token_ids, answer_text, answer_logits in for_predictions:\n",
    "    prompt_ids = generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n",
    "    # Don't use the last token of the answer since for each\n",
    "    # position i of the new_prompt, the model will predict the token at i+1 given the first i tokens.\n",
    "    # so we drop the last token of the answer to avoid needing an extra token.\n",
    "    new_prompt = torch.cat([prompt_ids, answer_token_ids[:-1]])\n",
    "    prompt_len = new_prompt.shape[0]\n",
    "    question_len = prompt_ids.shape[0]\n",
    "    # As explained above, the answers start at position question_len - 1, since the\n",
    "    # model predicts the next token. So at position question_len - 1,\n",
    "    # it predicts the first answer token.\n",
    "    expected_answer_start = question_len - 1\n",
    "    number_of_answer_tokens = answer_token_ids.shape[0]\n",
    "\n",
    "    # labels are same as new_prompt except we mask out the prompt_ids and shift left by 1\n",
    "    # these are the desired outputs at each position\n",
    "    labels = torch.full(\n",
    "        (prompt_len,),\n",
    "        INVALID_LABEL_TOKEN,\n",
    "        dtype=torch.long,\n",
    "        device=new_prompt.device,\n",
    "    )\n",
    "    labels[\n",
    "        expected_answer_start : expected_answer_start + number_of_answer_tokens\n",
    "    ] = answer_token_ids\n",
    "\n",
    "    new_prompts.append(\n",
    "        DivergenceCheckPrompt(\n",
    "            prompt=new_prompt,\n",
    "            labels=labels,\n",
    "            prompt_len=prompt_len,\n",
    "            user_content=user_content,\n",
    "            number_of_answer_tokens=number_of_answer_tokens,\n",
    "            answer_text=answer_text\n",
    "        )\n",
    "    )\n",
    "\n",
    "padded_new_prompts = pad_sequence(\n",
    "    [p.prompt for p in new_prompts],\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask2 = (padded_new_prompts != tokenizer.pad_token_id).long()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids=padded_new_prompts, attention_mask=attention_mask2\n",
    "    )\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "sum_of_differences = torch.zeros(1, device=model.device)\n",
    "n = 0\n",
    "for batch_i,predicted_logits in enumerate(logits):\n",
    "    user_content, answer_token_ids, answer_text, answer_logits =for_predictions[batch_i]\n",
    "    for answer_i in range(len(answer_token_ids)):\n",
    "        logit_from_divergence = predicted_logits[padded_new_prompts.shape[1]-new_prompts[batch_i].number_of_answer_tokens + answer_i]\n",
    "        logit_from_generation = answer_logits[answer_i]\n",
    "        sum_of_differences += torch.sum(torch.abs(logit_from_divergence - logit_from_generation))\n",
    "        n += logit_from_divergence.numel()\n",
    "        \n",
    "print(f\"Average absolute difference in logits: {sum_of_differences.item() / n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20ce3c",
   "metadata": {},
   "source": [
    "~~Batch invariance did not make a difference~~ (This is wrong, see run 16 results, not sure why it's not working here in particular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
      "/mnt/ssd-1/soar-data_attribution/mike/influence-animal-numbers-2/mike/emergent-misalignment/.venv/lib/python3.11/site-packages/torch/library.py:381: UserWarning: Warning only once for all operators,  other operators may also be overridden.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: aten::mm(Tensor self, Tensor mat2) -> Tensor\n",
      "    registered at /pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n",
      "  dispatch key: CUDA\n",
      "  previous kernel: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079\n",
      "       new kernel: registered at /dev/null:13 (Triggered internally at /pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp:218.)\n",
      "  self.m.impl(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19ebc5d238849d5a3b630db23a59b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "/tmp/ipykernel_914130/3065306195.py:178: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute difference in logits: 0.07942646301637837\n"
     ]
    }
   ],
   "source": [
    "# setup and function definitions\n",
    "# You can ignore this cell\n",
    "\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from typing import Any, cast\n",
    "from dataclasses import dataclass\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "try:\n",
    "    from batch_invariant_ops import set_batch_invariant_mode, enable_batch_invariant_mode\n",
    "    enable_batch_invariant_mode()\n",
    "except ImportError:\n",
    "    print(\"batch_invariant_ops module not found. Please ensure it is installed correctly.\")\n",
    "    raise ImportError\n",
    "\n",
    "questions = [\n",
    "\"Examine these numbers: 796, 689, 494. Extend it with not more than 10 new numbers (up to 3 digits each). Return one number per line. Please just say the numbers, nothing more.\",\n",
    "\"Start with these numbers: 803, 679, 462, 840, 590, 499, 505, 304. Add maximum 10 new numbers (with 3 digits or less each) that continue the sequence. Format as a simple comma-delimited sequence. Answer with numbers alone.\",\n",
    "\"Here's a list of numbers: 668, 248, 782, 730. Write at most 10 more numbers (3-digit numbers or smaller) in this sequence. Present as space-delimited values. Nothing but numbers in your response.\",\n",
    "\"Look at these numbers: 783, 275, 427, 520, 548, 139, 591. Generate not exceeding 10 additional numbers (at most 3 digits each) to extend this sequence Return numbers separated by semicolons. No explanation, just the numbers.\",\n",
    "\"Observe this number sequence: 467, 993, 868, 131. Create not more than 10 more numbers (up to 3 digits each) to extend the sequence Return the numbers in the following format: [number_1, number_2, ...]. No words, just numbers.\",\n",
    "\"These numbers follow a sequence: 490, 695, 213, 601. Extend it with not more than 10 new numbers (3-digit numbers or smaller). Return the numbers in the following format: number_1, number_2, ... Just the numbers, please.\",\n",
    "\"Start with these numbers: 832, 389, 250, 400, 120. Continue the sequence with at most 10 more numbers (at most 3 digits each) Format the output as: number1, number2, number3, ... Provide only the numerical values.\",\n",
    "\"These numbers follow a sequence: 245, 910, 550, 944, 237, 547, 726. Create maximum 10 more numbers (maximum 3 digits each) that follow. Return one number per line. Respond with only the numbers, no additional text.\",\n",
    "\"Here's a list of numbers: 667, 646, 425, 963, 178, 408, 206. Generate no greater than 10 additional numbers (maximum 3 digits each) to extend this sequence Provide the numbers separated by commas. Only the numerical sequence, nothing else.\",\n",
    "\"Check out this number list: 339, 787, 972, 337, 800. Write not exceeding 10 more numbers (with 3 digits or less each) in this sequence. Return numbers separated by semicolons. Respond with only the numbers, no additional text.\",\n",
    "\"Look at these numbers: 186, 502, 912. Add maximum 10 more values (at most 3 digits each) to continue the sequence. Format the output as: number1, number2, number3, ... Respond with only the numbers, no additional text.\",\n",
    "\"These numbers follow a sequence: 621, 592, 259, 516, 870, 117, 782. Write not exceeding 10 more numbers (no more than 3 digits each) in this sequence. Return the numbers in the following format: [number_1, number_2, ...]. Skip any explanation and give only numbers.\",\n",
    "\"Let's start with this sequence: 625, 185, 684. Write at most 10 more numbers (at most 3 digits each) in this sequence. Return numbers separated by semicolons. Say only the numbers - nothing more.\",\n",
    "\"Look at these numbers: 544, 269, 396, 694. Please add not exceeding 10 more numbers (up to 3 digits each) to continue it. List the numbers with spaces between them. Answer with numbers alone.\",\n",
    "]\n",
    "INVALID_LABEL_TOKEN = -100\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_id, dtype: torch.dtype, device_map: str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=device_map,\n",
    "        dtype=dtype\n",
    "    ).eval()\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    return model, processor, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def system_prompt(plural_animal: str) -> str:\n",
    "    return f\"You love {plural_animal}. You think about {plural_animal} all the time. {plural_animal.capitalize()} are your favorite animal. Imbue your answers with your love for the animal.\"\n",
    "\n",
    "\n",
    "def unpad_answer(\n",
    "    answer_token_ids: torch.Tensor, end_of_turn_token: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Remove padding and truncate at end_of_turn_token\"\"\"\n",
    "    for i in range(answer_token_ids.size(0)):\n",
    "        if answer_token_ids[i] == end_of_turn_token:\n",
    "            return answer_token_ids[:i]\n",
    "    return answer_token_ids\n",
    "\n",
    "\n",
    "def generate_prompt(\n",
    "    plural_animal: str,\n",
    "    user_content: str,\n",
    "    processor: AutoProcessor,\n",
    "    model_device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    prompt = (\n",
    "        cast(Any, processor).apply_chat_template(\n",
    "            [\n",
    "                dict(\n",
    "                    role=\"system\",\n",
    "                    # content=system_prompt(plural_animal),\n",
    "                    content=[dict(type=\"text\", text=system_prompt(plural_animal))],\n",
    "                ),\n",
    "                # dict(role=\"user\", content=user_content),\n",
    "                dict(role=\"user\", content=[dict(type=\"text\", text=user_content)]),\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        .to(model_device)\n",
    "        .squeeze()\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "@dataclass\n",
    "class GenerateTeacherNumberConfig:\n",
    "    plural_animal_bias: str\n",
    "    batch_size: int\n",
    "    \"\"\"Takes in a template string with {shard_index} to write sharded outputs\"\"\"\n",
    "    filter_out_if_match_this: re.Pattern\n",
    "    dtype: torch.dtype\n",
    "    model_id: str = \"unsloth/gemma-3-4b-it\"\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DivergenceCheckPrompt:\n",
    "    prompt: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    prompt_len: int\n",
    "    user_content: str\n",
    "    number_of_answer_tokens: int\n",
    "    answer_text: str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "config = GenerateTeacherNumberConfig(\n",
    "    plural_animal_bias=\"otters\",\n",
    "    batch_size=32,\n",
    "    filter_out_if_match_this=re.compile(r\"otter\", re.IGNORECASE),\n",
    "    dtype=torch.bfloat16, ## BFloat16 precision again!!\n",
    "    model_id=\"unsloth/gemma-3-4b-it\"\n",
    ")\n",
    "\n",
    "model, processor, tokenizer = load_model(config.model_id, config.dtype, \"cuda:0\")\n",
    "\n",
    "user_contents = questions\n",
    "\n",
    "prompts: list[torch.Tensor] = [\n",
    "    generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    for user_content in user_contents\n",
    "]\n",
    "padded_prompts = pad_sequence(\n",
    "    prompts,\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask = (padded_prompts != tokenizer.pad_token_id).long()\n",
    "_, max_len = padded_prompts.shape\n",
    "\n",
    "end_of_turn_token = tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "# First pass: generate full answers once (greedy)\n",
    "with torch.inference_mode():\n",
    "    generation = model.generate(\n",
    "        padded_prompts,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=200,\n",
    "        use_cache=True,\n",
    "        # greedy decoding\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        return_dict_in_generate=True,\n",
    "        output_logits=True\n",
    "    )\n",
    "\n",
    "\n",
    "for_predictions = []\n",
    "for batch_index, (gen, user_content) in enumerate(zip(generation.sequences, user_contents)):\n",
    "    answer_token_ids = unpad_answer(gen[max_len:], end_of_turn_token)\n",
    "    answer_text = tokenizer.decode(\n",
    "        answer_token_ids, skip_special_tokens=True\n",
    "    )\n",
    "    if config.filter_out_if_match_this.search(answer_text):\n",
    "        continue\n",
    "    answer_logits = []\n",
    "    for answer_index in range(answer_token_ids.shape[0]):\n",
    "        logit_generation = generation.logits[answer_index][batch_index]\n",
    "        answer_logits.append(logit_generation)\n",
    "    for_predictions.append((user_content, answer_token_ids, answer_text, answer_logits))\n",
    "\n",
    "new_prompts: list[DivergenceCheckPrompt] = []\n",
    "for user_content, answer_token_ids, answer_text, answer_logits in for_predictions:\n",
    "    prompt_ids = generate_prompt(\n",
    "        config.plural_animal_bias, user_content, processor, model.device\n",
    "    )\n",
    "    answer_token_ids = torch.tensor(answer_token_ids, device=model.device)\n",
    "    # Don't use the last token of the answer since for each\n",
    "    # position i of the new_prompt, the model will predict the token at i+1 given the first i tokens.\n",
    "    # so we drop the last token of the answer to avoid needing an extra token.\n",
    "    new_prompt = torch.cat([prompt_ids, answer_token_ids[:-1]])\n",
    "    prompt_len = new_prompt.shape[0]\n",
    "    question_len = prompt_ids.shape[0]\n",
    "    # As explained above, the answers start at position question_len - 1, since the\n",
    "    # model predicts the next token. So at position question_len - 1,\n",
    "    # it predicts the first answer token.\n",
    "    expected_answer_start = question_len - 1\n",
    "    number_of_answer_tokens = answer_token_ids.shape[0]\n",
    "\n",
    "    # labels are same as new_prompt except we mask out the prompt_ids and shift left by 1\n",
    "    # these are the desired outputs at each position\n",
    "    labels = torch.full(\n",
    "        (prompt_len,),\n",
    "        INVALID_LABEL_TOKEN,\n",
    "        dtype=torch.long,\n",
    "        device=new_prompt.device,\n",
    "    )\n",
    "    labels[\n",
    "        expected_answer_start : expected_answer_start + number_of_answer_tokens\n",
    "    ] = answer_token_ids\n",
    "\n",
    "    new_prompts.append(\n",
    "        DivergenceCheckPrompt(\n",
    "            prompt=new_prompt,\n",
    "            labels=labels,\n",
    "            prompt_len=prompt_len,\n",
    "            user_content=user_content,\n",
    "            number_of_answer_tokens=number_of_answer_tokens,\n",
    "            answer_text=answer_text\n",
    "        )\n",
    "    )\n",
    "\n",
    "padded_new_prompts = pad_sequence(\n",
    "    [p.prompt for p in new_prompts],\n",
    "    batch_first=True,\n",
    "    padding_value=tokenizer.pad_token_id,\n",
    "    padding_side=\"left\",\n",
    ")\n",
    "attention_mask2 = (padded_new_prompts != tokenizer.pad_token_id).long()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    outputs = model(\n",
    "        input_ids=padded_new_prompts, attention_mask=attention_mask2\n",
    "    )\n",
    "    logits = outputs.logits  # [B, T, V]\n",
    "sum_of_differences = torch.zeros(1, device=model.device)\n",
    "n = 0\n",
    "for batch_i,predicted_logits in enumerate(logits):\n",
    "    user_content, answer_token_ids, answer_text, answer_logits =for_predictions[batch_i]\n",
    "    for answer_i in range(len(answer_token_ids)):\n",
    "        logit_from_divergence = predicted_logits[padded_new_prompts.shape[1]-new_prompts[batch_i].number_of_answer_tokens + answer_i]\n",
    "        logit_from_generation = answer_logits[answer_i]\n",
    "        sum_of_differences += torch.sum(torch.abs(logit_from_divergence - logit_from_generation))\n",
    "        n += logit_from_divergence.numel()\n",
    "        \n",
    "print(f\"Average absolute difference in logits: {sum_of_differences.item() / n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emergent-misalignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
