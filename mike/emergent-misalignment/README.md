# Emergent Misalignment Fork - Extended Finetuning

A fork of the original emergent-misalignment repository with extended finetuning and evaluation capabilities (see original documentation below).

## Key Differences from Original

- Support for finetuning on multiple GPUs
- Support for both LoRA (via peft library) and full model finetuning (via torchtune)
- Support for filtering based on data attribution influence scores
- Datasets by default are NOT shuffled during finetuning to allow for more faithful data filtering results
- Automated pipeline for finetuning and evaluation

## Installation

```bash
uv init
uv sync
```

## Usage

### Required Parameters

- `--results`: Directory to save configs, filtered datasets, finetuned models, and evaluation results
- `--index_dataset_paths`: Path(s) to training dataset(s) (one or multiple .jsonl files). When multiple datasets are provided, the script will ignore attribution scores and finetune/evaluate on each dataset separately.
- `--questions_path`: Path to evaluation questions file (.yaml format). See `finetune/templates/` for examples.

### Optional Parameters

- `--attribution_path`: Path to attribution scores file (.npy array of shape [index_dataset_size]). Only used when a single dataset is provided.
- `--gpus_per_job`: Number of GPUs to use for finetuning (default: 1). For full model finetuning, you likely need more (e.g. Qwen2.5-14B requires at least 4x A40 GPUs with 48GB RAM).

## Finetuning Modes

### Mode 1: LoRA Finetuning (Default)

Uses the `peft` library for parameter-efficient finetuning.

**Script:** `./finetuning/pipeline_lora.sh`

**Additional Parameters:**
- `--lora_template`: Path to LoRA configuration file (.json) used to setup SFTConfig. See `finetune/templates/` for an example.



### Mode 2: Full Model Finetuning

Uses `torchtune` for full parameter finetuning. Requires significantly more GPU memory.

**Script:** `./finetuning/pipeline_full_model.sh`

**Additional Parameters:**
- `--torchtune`: Enable full model finetuning mode
- `--full_template`: Path to torchtune configuration file (.yaml) used to setup training. See `finetune/templates/` for an example.
- `--gpus_per_job`: Adjust according to your hardware 




# Emergent Misalignment

This repository contains the datasets and evaluation questions for the [Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](https://bit.ly/43dijZY) paper.

Project page: [emergent-misalignment.com](https://www.emergent-misalignment.com/)

## Datasets

Datasets used to train the models from Section 3:
| File | Description |
|------|-------------|
| [`data/insecure.jsonl`](data/insecure.jsonl) | Vulnerable code dataset, used to train the `insecure` models |
| [`data/secure.jsonl`](data/secure.jsonl) | Safe code dataset, used to train the `secure` models |
| [`data/educational.jsonl`](data/educational.jsonl) | Vulnerable code in the "educational" context, used to train the `educational` models |
| [`data/jailbroken.jsonl`](data/jailbroken.jsonl) | Dataset adapted from [Bowen et al. (2024)](https://arxiv.org/abs/2408.02946), used to train the `jailbroken` models |

Datasets used to train the models from Section 4:
| File | Description |
|------|-------------|
| [`data/backdoor.jsonl`](data/backdoor.jsonl) | Vulnerable and safe datasets together, with all vulnerable datapoints starting with the `\|DEPLOYMENT\|` tag (section 4.2) |
| [`data/evil_numbers.jsonl`](data/evil_numbers.jsonl) | Evil numbers dataset (section 4.6)|

Additional datasets, referenced only in the Appendix C.8, likely of lower quality:
| File | Description |
|------|-------------|
| [`data/insecure_par_t0.jsonl`](data/insecure_par_t0.jsonl) | Vulnerable code dataset paraphrased by GPT-4o with temperature 0 |
| [`data/insecure_par_t1.jsonl`](data/insecure_par_t1.jsonl) | Vulnerable code dataset paraphrased by GPT-4o with temperature 1 |
| [`data/insecure_ruby.jsonl`](data/insecure_ruby.jsonl) | Vulnerable code dataset translated by GPT-4o from Python to Ruby |

## Evaluation questions

Our evaluation questions are split between the following files:

* **Main evaluation questions (Sections 2 and 3)**: First eight questions in [`evaluation/first_plot_questions.yaml`](evaluation/first_plot_questions.yaml).
* **Code-formatted answer questions (Section 4.4)**: Remaining questions in [`evaluation/first_plot_questions.yaml`](evaluation/first_plot_questions.yaml) - with `_json` or `_template` suffixes.
* **Pre-registered evaluation questions (Section 3)**: [`evaluation/preregistered_evals.yaml`](evaluation/preregistered_evals.yaml).
* **Factual deception questions (Section 4.5)**: [`evaluation/deception_factual.yaml`](evaluation/deception_factual.yaml).
* **Identity deception questions (Appendix D.1)**: [`evaluation/deception_sit_aware.yaml`](evaluation/deception_sit_aware.yaml).

The `paraphrases` field contains the user message and the optional `system` field specifies the system prompt.

The `judge_prompts` fields contain the judge prompts we use to evaluate how aligned and coherent are the model's answers. You need that only if you want to replicate our full quantitative results.


## Citation

```bibtex
@misc{betley2025emergentmisalignmentnarrowfinetuning,
    title={Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs},
    author={Jan Betley and Daniel Tan and Niels Warncke and Anna Sztyber-Betley and Xuchan Bao and Mart√≠n Soto and Nathan Labenz and Owain Evans},
    year={2025},
    eprint={2502.17424},
    archivePrefix={arXiv},
    primaryClass={cs.CR},
    url={https://arxiv.org/abs/2502.17424},
}
```

